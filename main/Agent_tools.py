from matplotlib import pyplot as plt
from matplotlib.ticker import FuncFormatter
from api_caller import call_sam2_api
import base64
from PIL import Image, ImageDraw
import matplotlib
matplotlib.use("Agg")
import math
from openai import OpenAI
import os
import cv2
import json
import numpy as np
import threading
import os
import requests
from typing import Dict, Any, Optional
from typing import Dict, Any, List

import json
import os
import datetime
import uuid
#ä¸€ã€DeepSeek / LLM å†³ç­–ä¸å¤æ ¸ç›¸å…³
# å°† DeepSeek è¾“å‡º JSON è½¬æ¢ä¸º report_api å¯ç”¨æ ¼å¼
import json
import datetime


def _safe_load(obj, name=""):
    """
    å·¥ç¨‹çº§å…œåº•ï¼š
    - dict / list â†’ åŸæ ·è¿”å›
    - str(json) â†’ json.loads
    - å…¶ä»– â†’ None
    """
    if isinstance(obj, (dict, list)):
        return obj
    if isinstance(obj, str):
        try:
            return json.loads(obj)
        except Exception:
            print(f"âš ï¸ {_safe_load.__name__}: failed to load {name}")
            return None
    return None


def parse_deepseek_json(deepseek_json, px_to_m=0.001, start_depth_m=4000):
    """
    è§£æ DeepSeek æ™ºèƒ½ä½“è¾“å‡º JSONï¼ˆExecutor é€€åŒ–å®‰å…¨ç‰ˆï¼‰

    - è£‚ç¼ï¼šæ¥è‡ª UNetï¼ˆfractureï¼‰
    - å­”æ´ï¼šæ¥è‡ª vug_results
    - æ·±åº¦ï¼špx â†’ m ç»Ÿä¸€æ¢ç®—
    """

    # ======================================================
    # 0ï¸âƒ£ é¡¶å±‚ JSON ä¿®å¤
    # ======================================================
    print("ENTRY deepseek_json type:", type(deepseek_json))

    deepseek_json = _safe_load(deepseek_json, "deepseek_json")
    if deepseek_json is None:
        raise ValueError("âŒ deepseek_json is invalid")

    # Executor å¸¸è§åŒ…ä¸€å±‚ report.result_json
    if "deepseek_json" in deepseek_json:
        deepseek_json = deepseek_json["deepseek_json"]

    deepseek_json = _safe_load(deepseek_json, "deepseek_json")
    print("deepseek_json final type:", type(deepseek_json))

    # ======================================================
    # 1ï¸âƒ£ YOLOï¼ˆä»…æ£€æŸ¥ç»“æ„ï¼Œä¸å‚ä¸å®šé‡ï¼‰
    # ======================================================
    yolo = _safe_load(deepseek_json.get("yolo_result", {}), "yolo_result")
    print("yolo_result type:", type(yolo))

    detections = []
    if isinstance(yolo, dict):
        detections = _safe_load(yolo.get("detections", []), "detections") or []

    print("detections type:", type(detections))
    if isinstance(detections, list):
        for i, d in enumerate(detections[:3]):
            print(f"detections[{i}] type:", type(d))

    # ======================================================
    # 2ï¸âƒ£ è£‚ç¼è§£æï¼ˆUNetï¼‰
    # ======================================================
    fractures = []

    unet_results = deepseek_json.get("unet_results")
    unet_results = _safe_load(unet_results, "unet_results")

    print("unet_results type:", type(unet_results))

    all_metrics = []

    def collect_metrics(obj):
        """
        é€’å½’æ”¶é›†æ‰€æœ‰ metrics_list
        """
        if isinstance(obj, dict):
            for k, v in obj.items():
                if k == "metrics_list" and isinstance(v, list):
                    all_metrics.extend(v)
                else:
                    collect_metrics(v)
        elif isinstance(obj, list):
            for item in obj:
                collect_metrics(item)

    collect_metrics(unet_results)

    print(f"ğŸ§¬ collected metrics count = {len(all_metrics)}")

    for m in all_metrics:
        if not isinstance(m, dict):
            continue

        y_offset = m.get("y_offset", 0)
        D_px = m.get("D", 0)

        depth_m = start_depth_m + (y_offset + D_px) * px_to_m

        fractures.append({
            "length_mm": m.get("length_mm", 0),
            "dip_angle_deg": m.get("å€¾è§’_deg", 0),
            "depth_m": round(depth_m, 3),
            "area_mm2": m.get("area_mm2", 0),
            "strike_deg": m.get("èµ°å‘_deg"),
            "source": m.get("_model_id", "unet")
        })

    print(f"ğŸ§± Parsed fractures: {len(fractures)}")

    # ======================================================
    # 3ï¸âƒ£ å­”æ´è§£æï¼ˆVUGï¼‰
    # ======================================================
    vugs = []

    vug_results = deepseek_json.get("vug_results")
    vug_results = _safe_load(vug_results, "vug_results")

    print("vug_results type:", type(vug_results))

    if isinstance(vug_results, list):
        for model_vug in vug_results:
            if not isinstance(model_vug, dict):
                continue
            window_metrics = _safe_load(model_vug.get("window_metrics", []), "vug.window_metrics") or []

            for v in window_metrics:
                if not isinstance(v, dict):
                    continue

                depth_start_mm = v.get("depth_start_mm")
                depth_end_mm = v.get("depth_end_mm")
                if depth_start_mm is None or depth_end_mm is None:
                    continue

                depth_m = (depth_start_mm + depth_end_mm) / 2.0 / 1000.0

                vugs.append({
                    "vug_count": v.get("vug_count", 0),
                    "area_mm2": v.get("total_area_mm2", 0),
                    "depth_m": round(depth_m, 3),
                    "CVPA": v.get("CVPA", 0),
                    "CDENS": v.get("CDENS", 0),
                    "CSIZE": v.get("CSIZE", 0),
                    "source": model_vug.get("model_id", "unet_vug")
                })
    elif isinstance(vug_results, dict):
        # ä¿ç•™å¯¹æ—§æ ¼å¼çš„å…¼å®¹
        window_metrics = _safe_load(vug_results.get("window_metrics", []), "vug.window_metrics") or []
        for v in window_metrics:
            if not isinstance(v, dict):
                continue
            depth_start_mm = v.get("depth_start_mm")
            depth_end_mm = v.get("depth_end_mm")
            if depth_start_mm is None or depth_end_mm is None:
                continue
            depth_m = (depth_start_mm + depth_end_mm) / 2.0 / 1000.0
            vugs.append({
                "vug_count": v.get("vug_count", 0),
                "area_mm2": v.get("total_area_mm2", 0),
                "depth_m": round(depth_m, 3),
                "CVPA": v.get("CVPA", 0),
                "CDENS": v.get("CDENS", 0),
                "CSIZE": v.get("CSIZE", 0),
                "source": "unet_vug"
            })

    print(f"ğŸ•³ï¸ Parsed vugs: {len(vugs)}")

    # ======================================================
    # 4ï¸âƒ£ æ±‡æ€»è¾“å‡º
    # ======================================================
    result = {
        "timestamp": deepseek_json.get(
            "timestamp", datetime.datetime.now().isoformat()
        ),
        "modules_used": ["YOLO", "UNet", "SAM2"],
        "params_used": deepseek_json.get("params_used", {}),
        "fractures": fractures,
        "vugs": vugs,
        "reliability_score": "é«˜"
    }

    return result

def generate_comprehensive_report2(
    result: Any,
    final_image: str,
    log=print,
    report_api_url: str = "http://127.0.0.1:9095/generate_comprehensive_report",
    timeout: int = 120
) -> Dict[str, Optional[str]]:
    """
    Generate comprehensive geological report via report service.
    Returns structured output compatible with Executor PLAN:
    {
        "report": {
            "report_path": str or None,
            "report_preview": str or None
        },
        "status": "success" | "fallback" | "failed"
    }
    """

    # =========================================================
    # 0ï¸âƒ£ logging å…¼å®¹
    # =========================================================
    if isinstance(log, str):
        if log == "print":
            log = print
        else:
            raise ValueError(f"Unknown log function: {log}")

    # =========================================================
    # 1ï¸âƒ£ è¾“å…¥æ£€æŸ¥ & æ ‡å‡†åŒ–ï¼ˆğŸ”¥ å…³é”®ï¼‰
    # =========================================================
    if not isinstance(result, dict):
        raise ValueError("result must be dict")

    # --- params_used ---
    params_used = result.get("params_used")
    if not isinstance(params_used, dict):
        params_used = {}

    # --- fractures ---
    fractures = result.get("fractures") or []
    if not isinstance(fractures, list):
        fractures = []

    # ç»™ fracture è¡¥â€œæŠ¥å‘Šå‹å¥½å­—æ®µâ€
    normalized_fractures = []
    for f in fractures:
        if not isinstance(f, dict):
            continue
        normalized_fractures.append({
            "length_mm": f.get("length_mm", 0),
            "area_mm2": f.get("area_mm2", 0),
            "depth_m": f.get("depth_m"),
            "dip_angle_deg": f.get("dip_angle_deg"),
            "dip": f.get("dip_angle_deg"),          # â­ åˆ«å
            "strike_deg": f.get("strike_deg"),
            "azimuth": f.get("strike_deg"),         # â­ åˆ«å
            "source": f.get("source", "unknown")
        })

    # --- vugs ---
    vugs = result.get("vugs") or []
    print(vugs)
    if not isinstance(vugs, list):
        vugs = []

    # --- modules_used ---
    modules_used = result.get("modules_used") or []
    if not isinstance(modules_used, list):
        modules_used = []

    # =========================================================
    # 2ï¸âƒ£ ç»„è£…â€œæŠ¥å‘Šå®‰å…¨ payloadâ€
    # =========================================================
    safe_result = {
        "timestamp": result.get("timestamp"),
        "modules_used": modules_used,
        "params_used": params_used,
        "fractures": normalized_fractures,
        "vugs": vugs,
        "reliability_score": result.get("reliability_score", "æœªçŸ¥")
    }

    # debug
    log("ğŸ“¦ report.result_json keys:", safe_result.keys())
    log("fractures count:", len(safe_result["fractures"]))
    log("vugs count:", len(safe_result["vugs"]))

    payload = {
        "result": safe_result,
        "image_path": final_image,
        "image_url": final_image
    }

    # =========================================================
    # 3ï¸âƒ£ è°ƒç”¨æŠ¥å‘ŠæœåŠ¡
    # =========================================================
    try:
        log("ğŸ”¹ è°ƒç”¨æŠ¥å‘Šç”Ÿæˆæ¥å£ ...")
        import requests
        import os

        report_resp = requests.post(
            report_api_url,
            json=payload,
            timeout=timeout
        )

        if report_resp.status_code != 200:
            log(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: HTTP {report_resp.status_code}")
            return {
                "report": {"report_path": None, "report_preview": None},
                "status": "failed"
            }

        # =====================================================
        # 4ï¸âƒ£ JSON å“åº”
        # =====================================================
        try:
            resp_json = report_resp.json()
            report_out = {
                "report": {
                    "report_path": resp_json.get("report_path"),
                    "report_preview": resp_json.get("report_preview")
                },
                "status": "success"
            }

            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            print("ğŸ“¤ report status:", report_out.get("status"))
            print("ğŸ“„ report path:", report_out["report"]["report_path"])

            return report_out

        # =====================================================
        # 5ï¸âƒ£ fallbackï¼šé JSON â†’ Word
        # =====================================================
        except Exception:
            log("âš ï¸ æŠ¥å‘Šæ¥å£è¿”å›é JSONï¼Œä½¿ç”¨ fallback Word")

            report_text = report_resp.text.strip()

            from docx import Document
            from docx.shared import Inches

            doc = Document()
            doc.add_heading("ç”µæˆåƒç»¼åˆåœ°è´¨åˆ†ææŠ¥å‘Š", level=1)

            for line in report_text.split("\n"):
                line = line.strip()
                if not line:
                    continue
                if line.startswith("#"):
                    doc.add_heading(
                        line.replace("#", "").strip(),
                        level=min(line.count("#"), 4)
                    )
                elif line.startswith("- "):
                    doc.add_paragraph(line[2:], style="List Bullet")
                else:
                    doc.add_paragraph(line)

            if final_image and os.path.exists(final_image):
                doc.add_picture(final_image, width=Inches(5.5))

            report_path = "DeepSeek_Report_TCA3.docx"

            doc.save(report_path)

            report_out = {
                "report": {
                    "report_path": report_path,
                    "report_preview": report_text[:500]
                },
                "status": "fallback"
            }

            print("ğŸ“¤ report status:", report_out.get("status"))
            print("ğŸ“„ report path:", report_out["report"]["report_path"])

            return report_out

    except Exception as e:
        log(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆæ—¶å‡ºç°å¼‚å¸¸: {e}")
        return {
            "report": {"report_path": None, "report_preview": None},
            "status": "failed"
        }
def generate_comprehensive_report(
    result: Any,
    final_image: str,
    log=print,
    report_api_url: str = "http://127.0.0.1:9095/generate_comprehensive_report",
    timeout: int = 120
) -> Dict[str, Optional[str]]:
    """
    Generate comprehensive geological report via report service.
    Returns structured output compatible with Executor PLAN:
    {
        "report.report_path": str or None,
        "report.report_preview": str or None,
        "report.status": "success" | "fallback" | "failed"
    }
    """

    # =========================================================
    # 0ï¸âƒ£ logging å…¼å®¹
    # =========================================================
    if isinstance(log, str):
        if log == "print":
            log = print
        else:
            raise ValueError(f"Unknown log function: {log}")

    # =========================================================
    # 1ï¸âƒ£ è¾“å…¥æ£€æŸ¥ & æ ‡å‡†åŒ–ï¼ˆğŸ”¥ å…³é”®ï¼‰
    # =========================================================
    if not isinstance(result, dict):
        raise ValueError("result must be dict")

    # --- params_used ---
    params_used = result.get("params_used")
    if not isinstance(params_used, dict):
        params_used = {}

    # --- fractures ---
    fractures = result.get("fractures") or []
    if not isinstance(fractures, list):
        fractures = []

    # ç»™ fracture è¡¥â€œæŠ¥å‘Šå‹å¥½å­—æ®µâ€
    normalized_fractures = []
    for f in fractures:
        if not isinstance(f, dict):
            continue
        normalized_fractures.append({
            "length_mm": f.get("length_mm", 0),
            "area_mm2": f.get("area_mm2", 0),
            "depth_m": f.get("depth_m"),
            "dip_angle_deg": f.get("dip_angle_deg"),
            "dip": f.get("dip_angle_deg"),          # â­ åˆ«å
            "strike_deg": f.get("strike_deg"),
            "azimuth": f.get("strike_deg"),         # â­ åˆ«å
            "source": f.get("source", "unknown")
        })

    # --- vugs ---
    vugs = result.get("vugs") or []
    print(vugs)
    if not isinstance(vugs, list):
        vugs = []

    # --- modules_used ---
    modules_used = result.get("modules_used") or []
    if not isinstance(modules_used, list):
        modules_used = []

    # =========================================================
    # 2ï¸âƒ£ ç»„è£…â€œæŠ¥å‘Šå®‰å…¨ payloadâ€
    # =========================================================
    safe_result = {
        "timestamp": result.get("timestamp"),
        "modules_used": modules_used,
        "params_used": params_used,
        "fractures": normalized_fractures,
        "vugs": vugs,
        "reliability_score": result.get("reliability_score", "æœªçŸ¥")
    }

    # debug
    log("ğŸ“¦ report.result_json keys:", safe_result.keys())
    log("fractures count:", len(safe_result["fractures"]))
    log("vugs count:", len(safe_result["vugs"]))

    payload = {
        "result": safe_result,
        "image_path": final_image,
        "image_url": final_image
    }

    # =========================================================
    # 3ï¸âƒ£ è°ƒç”¨æŠ¥å‘ŠæœåŠ¡
    # =========================================================
    try:
        log("ğŸ”¹ è°ƒç”¨æŠ¥å‘Šç”Ÿæˆæ¥å£ ...")
        import requests
        import os

        report_resp = requests.post(
            report_api_url,
            json=payload,
            timeout=timeout
        )

        if report_resp.status_code != 200:
            log(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: HTTP {report_resp.status_code}")
            return {
                "report.report_path": None,
                "report.report_preview": None,
                "report.status": "failed"
            }

        # =====================================================
        # 4ï¸âƒ£ JSON å“åº”
        # =====================================================
        try:
            resp_json = report_resp.json()
            report_out = {
                "report.report_path": resp_json.get("report_path"),
                "report.report_preview": resp_json.get("report_preview"),
                "report.status": "success"
            }

            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            print("ğŸ“¤ report status:", report_out["report.status"])
            print("ğŸ“„ report path:", report_out["report.report_path"])

            return report_out

        # =====================================================
        # 5ï¸âƒ£ fallbackï¼šé JSON â†’ Word
        # =====================================================
        except Exception:
            log("âš ï¸ æŠ¥å‘Šæ¥å£è¿”å›é JSONï¼Œä½¿ç”¨ fallback Word")

            report_text = report_resp.text.strip()

            from docx import Document
            from docx.shared import Inches

            doc = Document()
            doc.add_heading("ç”µæˆåƒç»¼åˆåœ°è´¨åˆ†ææŠ¥å‘Š", level=1)

            for line in report_text.split("\n"):
                line = line.strip()
                if not line:
                    continue
                if line.startswith("#"):
                    doc.add_heading(
                        line.replace("#", "").strip(),
                        level=min(line.count("#"), 4)
                    )
                elif line.startswith("- "):
                    doc.add_paragraph(line[2:], style="List Bullet")
                else:
                    doc.add_paragraph(line)

            if final_image and os.path.exists(final_image):
                doc.add_picture(final_image, width=Inches(5.5))

            report_path = "DeepSeek_Report_TCA3.docx"

            doc.save(report_path)

            report_out = {
                "report.report_path": report_path,
                "report.report_preview": report_text[:500],
                "report.status": "fallback"
            }

            print("ğŸ“¤ report status:", report_out["report.status"])
            print("ğŸ“„ report path:", report_out["report.report_path"])

            return report_out

    except Exception as e:
        log(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆæ—¶å‡ºç°å¼‚å¸¸: {e}")
        return {
            "report.report_path": None,
            "report.report_preview": None,
            "report.status": "failed"
        }
# ===== DeepSeek å†³ç­– =====

import json
import re
from local_llm import call_local_llm
def safe_json_extract(text):
    """
    å¤„ç† ```json åŒ…è£¹ æˆ– å¤šä½™æ–‡æœ¬
    """
    text = text.strip()

    # å»æ‰ ```json ``` åŒ…è£¹
    if text.startswith("```"):
        text = re.sub(r"```.*?\n", "", text)
        text = text.replace("```", "")

    # æå–ç¬¬ä¸€ä¸ª JSON å¯¹è±¡
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        return match.group(0)

    return text

import json

def deepseek_filter_curves_safe(curves_metrics, x_points_list, image_height_px, image_width_px,
                                min_points=200, max_retries=3, flags=None, log_fn=None, strategy="default"):
    """
    âœ… åˆå¹¶ DeepSeek æ›²çº¿å¤æ ¸ + metrics é‡å†™
    - Step 1: é¢„å¤„ç†
    - Step 2: è°ƒç”¨æœ¬åœ° LLM (æ›¿ä»£åŸ DeepSeek API)
    - Step 3: å…œåº•é€»è¾‘
    - Step 4: æ ¹æ® flags å†³å®šæ˜¯å¦è¦†ç›–
    """
    if log_fn:
        log_fn("ğŸš€ Start deepseek_filter_and_overwrite")

    # ---------- Step 1: é¢„å¤„ç† ----------
    if not curves_metrics or not x_points_list:
        if log_fn:
            log_fn("âš ï¸ curves_metrics æˆ– x_points_list ä¸ºç©º")
        filtered_curves, analysis_log, pre_filtered = [], [], []
    else:
        pre_filtered = [(i, m) for i, m in enumerate(curves_metrics)
                        if i < len(x_points_list) and len(x_points_list[i]) >= min_points]
        if log_fn:
            log_fn(f"ğŸŸ¢ pre_filtered æ•°é‡: {len(pre_filtered)}")

        if not pre_filtered:
            filtered_curves, analysis_log = [], ["âš ï¸ æ²¡æœ‰æ›²çº¿æ»¡è¶³ min_points æ¡ä»¶"]
        else:
            # ---------- Step 2: ã€ä¿®æ”¹ç‚¹ã€‘ä½¿ç”¨æœ¬åœ° Ollama / LLM æ›¿ä»£ API ----------
            metrics_simple = [{"A": m.get("A"), "B": m.get("B"), "C": m.get("C"), "D": m.get("D")} for _, m in pre_filtered]
            try:
                params_json = json.dumps(metrics_simple, ensure_ascii=False)
            except:
                params_json = json.dumps(metrics_simple, ensure_ascii=True)

            prompt = generate_prompt("filter_curves", curves_params=params_json,
                                     image_width_px=image_width_px, image_height_px=image_height_px,
                                     strategy=strategy)

            if log_fn:
                log_fn(f"ğŸ”¹ Prompt å‘é€ç»™æœ¬åœ° LLM:\n{prompt[:500]}...")  # åªæ‰“å°å‰500å­—ç¬¦é˜²æ­¢è¿‡é•¿

            # ğŸ”¹ ä¿®æ”¹ç‚¹ï¼šè°ƒç”¨æœ¬åœ° LLM
            try:
                raw_output = call_local_llm(prompt, temperature=0)  # ã€ä¿®æ”¹ç‚¹ã€‘
                if log_fn:
                    log_fn(f"ğŸ”¹ LLM raw output:\n{str(raw_output)[:500]}...")  # å‰500å­—ç¬¦
                cleaned_output = safe_json_extract(raw_output)      # ã€ä¿®æ”¹ç‚¹ã€‘
                if log_fn:
                    log_fn(f"ğŸ”¹ cleaned_output:\n{cleaned_output[:500]}...")
                decision = json.loads(cleaned_output)              # ã€ä¿®æ”¹ç‚¹ã€‘

                valid_idx = decision.get("valid_curves", [])
                analysis_log = decision.get("analysis_log", [])
                filtered_curves = [pre_filtered[i][1] for i in valid_idx if i < len(pre_filtered)]

                if log_fn:
                    log_fn(f"ğŸŸ¢ LLM è¿”å›æœ‰æ•ˆæ›²çº¿æ•°é‡: {len(filtered_curves)}")

            except Exception as e:
                if log_fn:
                    log_fn(f"âš ï¸ æœ¬åœ° LLM å°è¯•å¤±è´¥: {e}")
                    log_fn(f"ğŸ”¹ raw_output: {repr(raw_output) if 'raw_output' in locals() else 'None'}")
                filtered_curves, analysis_log = [], []

            # ---------- Step 3: å…œåº•é€»è¾‘ ----------
            if not filtered_curves:
                for idx, m in pre_filtered:
                    A, B = abs(m.get("A", 0)), m.get("B", 1.0)
                    valid_mark = "valid" if B <= 0.05 and A <= image_height_px / 3 else "invalid"
                    if valid_mark == "valid":
                        filtered_curves.append(m)
                    analysis_log.append(f"æ›²çº¿{idx}: B={B}, |A|={A} => {valid_mark}")

    # ---------- Step 4: æ ¹æ® flags å†³å®šæ˜¯å¦è¦†ç›– ----------
    enable_reflection = False
    if flags and isinstance(flags, dict):
        enable_reflection = flags.get("enable_reflection", False)

    if enable_reflection:
        final_metrics = filtered_curves
        if log_fn:
            log_fn(f"ğŸ”„ è¦†ç›– metrics, æ•°é‡={len(final_metrics)}")
    else:
        final_metrics = curves_metrics
        if log_fn:
            log_fn(f"âš ï¸ flags æœªå¯ç”¨ï¼Œä¿æŒåŸ metrics, æ•°é‡={len(final_metrics)}")

    # ---------- Step 5: è¿”å› Executor æ ¼å¼ ----------
    return {
        "fracture_metrics_list": final_metrics,
        "reflection.curves_filtered": filtered_curves,
        "reflection.analysis_log": analysis_log,
        "reflection.pre_filtered": pre_filtered
    }

# ===== DeepSeek å†³ç­– =====

def deepseek_decide_models(user_input, yolo_results, strategy="default"):
    """
    æœ¬åœ° Ollama ç‰ˆæœ¬
    Semantic-Constrained Model Selection
    1ï¸âƒ£ æ ¹æ®ç”¨æˆ·è¾“å…¥ + YOLO ç»“æœç”Ÿæˆ prompt
    2ï¸âƒ£ è°ƒç”¨æœ¬åœ° LLM (Ollama æˆ–å…¶ä»–) å¾—åˆ° JSON å†³ç­–
    3ï¸âƒ£ è¿”å›ç™½åå•æ¨¡å‹ + å¯é€‰å‚æ•°
    """
    prompt = generate_prompt(
        "decide_models",
        user_input=user_input,
        yolo_results=yolo_results,
        strategy=strategy
    )

    try:
        # è°ƒç”¨æœ¬åœ° LLM
        raw_output = call_local_llm(prompt, temperature=0.2)

        # å°è¯•æå– JSON å†…å®¹
        cleaned_output = safe_json_extract(raw_output)
        decision = json.loads(cleaned_output)

        # å…è®¸çš„æ¨¡å‹ç™½åå•
        allowed_models = ["unet_Fracture", "unet_Induced_Fracture", "unet_Vug"]
        models = [m for m in decision.get("models", []) if m in allowed_models]

        # å…œåº•ï¼šè‡³å°‘è¿”å›ä¸€ä¸ªå¯æ‰§è¡Œæ¨¡å‹
        if not models:
            models = ["unet_Fracture"]


        # âœ… è¿”å›ç»“æœ
        return {
            "model_ids": models
        }

    except Exception as e:
        print(f"âš ï¸ æœ¬åœ° LLM æ¨¡å‹å†³ç­–å¤±è´¥: {e}")
        return {
            "model_ids": ["unet_Fracture"]
        }
def generate_prompt(task_type, user_input=None, yolo_results=None, curves_params=None,
                    image_width_px=None, image_height_px=None, strategy="default"):
    """

    ç”Ÿæˆä¸åŒç­–ç•¥çš„ Prompt
    task_type: "decide_models" æˆ– "filter_curves"
    strategy: "default", "zero-shot", "few-shot", "hard-constraint"
    """
    if task_type == "decide_models":
        base = "ä½ æ˜¯ä¸€ä½å›¾åƒåˆ†å‰²æ™ºèƒ½åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥å’ŒYOLOæ£€æµ‹ç»“æœè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„åœ°è´¨åˆ†å‰²æ¨¡å‹ã€‚è¯·ä¸¥æ ¼è¿”å› JSONã€‚"
        if strategy == "default":
            prompt = f"{base}\nç”¨æˆ·è¾“å…¥: {user_input}\nYOLOç»“æœ: {yolo_results}"
        elif strategy == "zero-shot":
            prompt = f"{base}\nç”¨æˆ·è¾“å…¥: {user_input}\nYOLOç»“æœ: {yolo_results}\nåªè¿”å›JSONï¼Œä¸è¦è§£é‡Šã€‚"
        elif strategy == "few-shot":
            prompt = f"""{base}
ç¤ºä¾‹ï¼š
ç”¨æˆ·è¾“å…¥: è£‚ç¼
YOLOç»“æœ: {{}}
è¾“å‡º: {{
  "models": ["unet_Fracture"],
  "parameters": {{}}
}}
ç”¨æˆ·è¾“å…¥: å­”æ´
YOLOç»“æœ: {{}}
è¾“å‡º: {{
  "models": ["unet_Vug"],
  "parameters": {{}}
}}
ç”¨æˆ·è¾“å…¥: è¯±å¯¼ç¼
YOLOç»“æœ: {{}}
è¾“å‡º: {{
  "models": ["unet_Induced_Fracture"],
  "parameters": {{}}
}}
ç”¨æˆ·è¾“å…¥: æ£€æµ‹å›¾ç‰‡
YOLOç»“æœ: ["Fracture", "Vug"]
è¾“å‡º: {{"models": ["unet_Fracture", "unet_Vug"], "parameters": {{}} }}

ç°åœ¨ç”¨æˆ·è¾“å…¥: {user_input}
YOLOç»“æœ: {yolo_results}
è¯·æ ¹æ®ç¤ºä¾‹é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚
"""
        elif strategy == "hard-constraint":
            prompt = f"""ä½ æ˜¯ä¸€ä½å›¾åƒåˆ†å‰²æ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æ„å›¾ä¸YOLOæ£€æµ‹ç»“æœè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„åœ°è´¨åˆ†å‰²æ¨¡å‹ã€‚
ä½ çš„ä»»åŠ¡ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ä¸­å‡ºç°â€œè£‚ç¼â€ï¼Œä»…ä½¿ç”¨ ["unet_Fracture"]ï¼›
2. å¦‚æœå‡ºç°â€œå­”æ´â€ï¼Œä»…ä½¿ç”¨ ["unet_Vug"]ï¼›
3. å¦‚æœå‡ºç°â€œè¯±å¯¼ç¼â€æˆ–â€œé’»äº•è¯±å¯¼è£‚ç¼â€ï¼Œä»…ä½¿ç”¨ ["unet_Induced_Fracture"]ï¼›
4. å¦‚æœç”¨æˆ·è¾“å…¥ä¸ºâ€œæ£€æµ‹å›¾ç‰‡â€æˆ–â€œåˆ†æå›¾ç‰‡â€ï¼Œåˆ™æ ¹æ® YOLO æ£€æµ‹ç»“æœè‡ªåŠ¨åŒ¹é…ï¼š
   - YOLOæ£€æµ‹ç»“æœä¸­åŒ…å« Fracture â†’ ä½¿ç”¨ ["unet_Fracture"]
   - YOLOæ£€æµ‹ç»“æœä¸­åŒ…å« Induced_Fracture â†’ ä½¿ç”¨ ["unet_Induced_Fracture"]
   - YOLOæ£€æµ‹ç»“æœä¸­åŒ…å« Vug â†’ ä½¿ç”¨ ["unet_Vug"]
5. å¦‚æœæ£€æµ‹ç»“æœåŒ…å«å¤šç§ç±»å‹ï¼Œå¯åŒæ—¶è¾“å‡ºå¤šä¸ªæ¨¡å‹ï¼›
6. å¦‚æœå‡ä¸ç¬¦åˆæ¡ä»¶ï¼Œåˆ™è¿”å› ["unet_Fracture"]ã€‚
è¾“å‡ºæ ¼å¼å›ºå®šä¸º JSONï¼š
{{
  "models": ["unet_Fracture", "unet_Vug"],
  "parameters": {{}}
}}
è¯·åªè¾“å‡ºJSONå†…å®¹ï¼Œä¸è¦è§£é‡Šã€‚"""
        else:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy}")

    elif task_type == "filter_curves":
        base = "ä½ æ˜¯åœ°è´¨å›¾åƒåˆ†æåŠ©æ‰‹ï¼Œæ ¹æ®æ›²çº¿å‚æ•°åˆ†ææ¯æ¡æ›²çº¿æ˜¯å¦æœ‰æ•ˆã€‚è¯·ä¸¥æ ¼è¾“å‡º JSON,ä¸è¦è§£é‡Šã€ä¸è¦æ·»åŠ è¯´æ˜ã€ä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ï¼Œåªè¾“å‡º JSON å¯¹è±¡ã€‚"
        if strategy in ["default", "zero-shot"]:
            prompt = (
                f"{base}\n"
                "ä½ æ˜¯ä¸€ååœ°è´¨æ›²çº¿åˆ†æåŠ©æ‰‹ï¼Œè¯·åŸºäºåœ°è´¨çŸ¥è¯†å’Œç”µæˆåƒæœ‰å…³çš„çŸ¥è¯†åˆ¤æ–­æ¯æ¡æ›²çº¿çš„æœ‰æ•ˆæ€§ã€‚\n\n"
                "ã€è¾“å‡ºè¦æ±‚ã€‘\n"
                "1. è¾“å‡ºå¿…é¡»æ˜¯åˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸èƒ½åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€æ³¨é‡Šæˆ–é¢å¤–è¯´æ˜ã€‚\n"
                "2. JSON å¯¹è±¡éœ€åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªé”®ï¼š\n"
                "   - \"analysis_log\": åŒ…å«æ¯æ¡æ›²çº¿çš„åˆ†æè¯´æ˜ã€‚\n"
                "   - \"valid_curves\": æœ‰æ•ˆæ›²çº¿ç´¢å¼•åˆ—è¡¨ã€‚\n"
                "   - \"invalid_curves\": æ— æ•ˆæ›²çº¿ç´¢å¼•åˆ—è¡¨ã€‚\n"
                "3. è‹¥æ— æ³•åˆ¤æ–­ï¼Œè¯·è¿”å›ï¼š\n"
                "{{\"analysis_log\": [], \"valid_curves\": [], \"invalid_curves\": []}}\n\n"
                f"è¾“å…¥æ•°æ®å¦‚ä¸‹ï¼š\nå›¾åƒå®½åº¦={image_width_px}, é«˜åº¦={image_height_px}, å‚æ•°={curves_params}\n\n"
                "è¯·ç›´æ¥è¾“å‡ºç¬¦åˆè¦æ±‚çš„ JSON å¯¹è±¡ã€‚"
            )
        elif strategy == "few-shot":
            prompt = (
                f"ä½ æ˜¯ä¸€ååœ°è´¨æµ‹äº•åˆ†æä¸“å®¶ï¼Œè¯·å­¦ä¹ ä»¥ä¸‹ç¤ºä¾‹çš„è¾“å…¥è¾“å‡ºæ ¼å¼ã€‚\n"
                "ä»»åŠ¡ï¼šåˆ¤æ–­æ¯æ¡æ›²çº¿æ˜¯å¦æœ‰æ•ˆï¼Œå¹¶è¾“å‡º JSON ç»“æœã€‚\n\n"
                "ã€é‡è¦è¦æ±‚ã€‘\n"
                "- ä½ å¿…é¡»åªè¾“å‡º JSON å¯¹è±¡ï¼Œä¸èƒ½è¾“å‡ºä»»ä½•è§£é‡Šã€å‰ç¼€ã€æ³¨é‡Šæˆ–è‡ªç„¶è¯­è¨€ã€‚\n"
                "- ä¸è¦è¾“å‡ºâ€œè¾“å‡º:â€æˆ–â€œç»“æœå¦‚ä¸‹:â€ï¼Œä¸è¦æ·»åŠ æ¢è¡Œè¯´æ˜ã€‚\n"
                "- è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå®ˆ JSON è¯­æ³•ã€‚\n\n"
                "ç¤ºä¾‹ï¼š\n"
                "è¾“å…¥: å›¾åƒå®½åº¦=472, é«˜åº¦=1422, å‚æ•°=[{{\"A\":50,\"B\":0.02}}, {{\"A\":700,\"B\":0.1}},{{\"A\":-66.71,\"B\":0.0132}}, {{\"A\":44,\"B\":0.0132}}, {{\"A\":500,\"B\":0.060}}, {{\"A\":-43.17,\"B\":0.0221}}, {{\"A\":68199.68,\"B\":0.0003 }},{{\"A\":7.62,\"B\":0.0647}} ]\n"
                "è¾“å‡º:\n"
                "{{\n"
                "  \"analysis_log\": [\n"
                "    \"æ›²çº¿0: A=50, B=0.02 âœ…\",\n"
                "    \"æ›²çº¿1: A=700, B=0.1 âŒ\",\n"
                "    \"æ›²çº¿2: B=0.0132ï¼Œï¼ŒA=-66.71, |A|=66.71 âœ…\",\n"
                "    \"æ›²çº¿3: B=0.0132 , A=44, |A|=44  âœ…\",\n"
                "    \"æ›²çº¿4: B=0.060, A=500, |A|=500  âŒ \",\n"
                "    \"æ›²çº¿5: B=0.0221 , A=-43.17, |A|=43.17 âœ… \",\n"
                "    \"æ›²çº¿6: B=0.0003 , A=68199.68, |A|=68199.68 âŒ \",\n"
                "    \"æ›²çº¿7: B=0.0647, A=7.62, |A|=7.62 âŒ \"\n"
                "  ],\n"
                "  \"valid_curves\": [0, 2, 3, 5],\n"
                "  \"invalid_curves\": [1, 4, 6, 7]\n"
                "}}\n\n"
                f"ç°åœ¨è¾“å…¥:\nå›¾åƒå®½åº¦={image_width_px}, é«˜åº¦={image_height_px}, å‚æ•°={curves_params}\n\n"
                "è¯·æ¨¡ä»¿ç¤ºä¾‹è¾“å‡ºï¼Œä»…è¿”å› JSON å¯¹è±¡ã€‚\n"
                "å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¯·è¿”å›ï¼š\n"
                "{{\"analysis_log\": [], \"valid_curves\": [], \"invalid_curves\": []}}"
            )

        elif strategy == "hard-constraint":
            prompt = f"""
ä½ æ˜¯åœ°è´¨å›¾åƒåˆ†æåŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®æ›²çº¿å‚æ•°åˆ¤æ–­å“ªäº›æ›²çº¿æœ‰æ•ˆã€‚è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ç”Ÿæˆè¾“å‡ºï¼š

ã€ä»»åŠ¡è¦æ±‚ã€‘
1. å¯¹è¾“å…¥çš„æ¯æ¡æ›²çº¿éƒ½ç”Ÿæˆä¸€æ¡æ—¥å¿—ï¼ˆå³ä½¿æ˜¯æ— æ•ˆæ›²çº¿ï¼Œä¹Ÿå¿…é¡»ç”Ÿæˆï¼‰ã€‚
2. åœ¨å¤„ç†æŒ¯å¹…å‚æ•° A æ—¶ï¼Œè¯·å–å…¶ç»å¯¹å€¼ï¼Œå› ä¸ºæŒ¯å¹…åº”ä¸ºæ­£æ•°ã€‚
3. åˆ¤æ–­æ ‡å‡†ï¼š
   - è‹¥ B <= 0.02 ä¸” |A| <= å›¾åƒé«˜åº¦ * 2/3ï¼Œåˆ™è¯¥æ›²çº¿æœ‰æ•ˆï¼ˆâœ…ï¼‰ï¼›
   - å¦åˆ™è§†ä¸ºæ— æ•ˆï¼ˆâŒï¼‰ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œä¸å…è®¸å‡ºç°é™¤ JSON å¤–çš„ä»»ä½•è§£é‡Šæˆ–æ–‡å­—ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š
{{
  "analysis_log": ["æ›²çº¿0: A=100 âœ…", "æ›²çº¿1: A=600 âŒ"],
  "valid_curves": [0],
  "invalid_curves": [1]
}}

ã€è¾“å…¥æ•°æ®ã€‘
å›¾åƒå®½åº¦ = {image_width_px}, é«˜åº¦ = {image_height_px}, å‚æ•° = {curves_params}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ‡å‡†è¾“å‡º JSONã€‚
"""
        else:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy}")
    else:
        raise ValueError(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}")

    return prompt





#äºŒã€YOLO / U-Net / SAM2 æ¨¡å‹è°ƒç”¨æ¥å£
# ===== è°ƒç”¨ U-Net API =====
# ===== U-Net API é…ç½® =====
# yolo_agent.py
import requests

YOLO_API_URL = "http://localhost:2000/analyze"  # è‹¥éƒ¨ç½²åœ¨è¿œç¨‹ï¼Œæ”¹ä¸ºå®é™…IP:ç«¯å£

def call_yolo_api(image_path: str, params: dict = {}):
    """
    å‘é€å›¾åƒåˆ° YOLO Flask APIï¼Œè¿”å›æ£€æµ‹ç»“æœï¼ˆåŒ…å« classã€bboxã€confidenceï¼‰
    :param image_path: æœ¬åœ°å›¾åƒè·¯å¾„
    :param params: å¯é€‰å‚æ•°ï¼Œæš‚æœªå¯ç”¨ï¼ˆä¿ç•™æ‰©å±•ï¼‰
    :return: dict {detections: [...]}
    """
    with open(image_path, 'rb') as f:
        files = {'image': f}
        try:
            response = requests.post(YOLO_API_URL, files=files, data=params)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ è°ƒç”¨YOLO APIå¤±è´¥ï¼š{e}")
            raise

UNET_API_URL = "http://127.0.0.1:7000/unet/{model_id}/segment"
def call_unet_api(model_id, image_path):
    with open(image_path, "rb") as f:
        files = {"roi": f}
        response = requests.post(UNET_API_URL.format(model_id=model_id), files=files)
    if response.status_code == 200:
        data = response.json()
        mask_base64 = data["mask"]
        mask_bytes = base64.b64decode(mask_base64)
        mask_path = f"{model_id}_{uuid.uuid4().hex}.png"

        #mask_path = os.path.join(temp_dir, f"{model_id}_{uuid.uuid4().hex}.png")
        with open(mask_path, "wb") as f:
            f.write(mask_bytes)
        return {"mask": mask_path}
    else:
        raise RuntimeError(f"âŒ U-Net APIè°ƒç”¨å¤±è´¥: {response.text}")

def call_sam2_box(image_path, box_coords):
    """
    ä½¿ç”¨ box æç¤ºè°ƒç”¨ SAM2 åˆ†å‰²
    :param image_path: è¾“å…¥å›¾åƒè·¯å¾„
    :param box_coords: [x_min, y_min, x_max, y_max]
    :return: {"mask": mask_path}
    """
    with open(image_path, "rb") as f:
        files = {"file": (image_path, f, "image/jpeg")}
        data = {"prompt_type": "box", "box_coords": str(box_coords)}
        resp = requests.post("http://127.0.0.1:3000/predict", files=files, data=data)
        resp.raise_for_status()
        result = resp.json()

    # ä¿å­˜ mask æ–‡ä»¶
    mask_base64 = result.get("mask")
    mask_bytes = base64.b64decode(mask_base64)
    mask_path = f"sam2_box_{uuid.uuid4().hex}.png"
    #mask_path = os.path.join(temp_dir, f"sam2_box_{uuid.uuid4().hex}.png")
    with open(mask_path, "wb") as f:
        f.write(mask_bytes)

    return {"mask": mask_path}
#ä¸‰ã€Mask ä¸å›¾åƒé¢„å¤„ç†
def save_base64_mask(mask_b64, save_path):
    """å°† base64 mask ä¿å­˜ä¸º PNG æ–‡ä»¶"""
    with open(save_path, "wb") as f:
        f.write(base64.b64decode(mask_b64))
    return save_path
# ===== Mask é¢„å¤„ç† =====
def preprocess_mask_for_analysis(mask_path, log_fn=None):
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask_img is None:
        raise RuntimeError(f"è¯»å– mask æ–‡ä»¶å¤±è´¥: {mask_path}")
    binary_mask = (mask_img > 0).astype(np.uint8) * 255
    nonzero_count = cv2.countNonZero(binary_mask)
    if log_fn:
        log_fn(f"ğŸ”¹ mask éé›¶åƒç´ æ•°: {nonzero_count}")
        if nonzero_count == 0:
            log_fn("âš ï¸ å½“å‰ mask å…¨ä¸ºç©ºç™½ï¼Œåˆ†æç»“æœå¯èƒ½æ— æ•ˆ")
    temp_mask_path = f"temp_mask_{uuid.uuid4().hex}.png"
    #temp_mask_path = os.path.join(temp_dir, f"temp_mask_{uuid.uuid4().hex}.png")
    cv2.imwrite(temp_mask_path, binary_mask)
    return temp_mask_path
def split_mask_to_contours(mask_path):
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    binary_mask = (mask_img > 0).astype(np.uint8)
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    single_masks = []
    for contour in contours:
        mask_single = np.zeros_like(binary_mask)
        cv2.drawContours(mask_single, [contour], -1, 255, -1)
        single_masks.append(mask_single)
    return single_masks
# ===== é¢œè‰²æ˜ å°„ =====


# SAM2 ä¸“ç”¨é¢œè‰²æ˜ å°„
SAM2_MAPPING = {
    "sam2_fracture": {"color": (0, 255, 0)},   # ç´«è‰²
    "sam2_vug": {"color": (255, 165, 0)}         # æ©™è‰²
}
MODEL_MAPPING = {
    "unet_Fracture": {"color": (255, 0, 0)},          # çº¢è‰²
    "unet_Induced_Fracture": {"color": (0, 0, 255)},  # è“è‰²
    "unet_Vug": {"color": (0, 255, 0)}               # ç»¿è‰²
}
def overlay_masks2(masks, model_ids, base_image_path, log_fn=None):
    """
    å°† U-Netï¼ˆè£‚ç¼ / å­”æ´ï¼‰+ SAM2 çš„æ©ç å åŠ åˆ°åŸå›¾ä¸Šï¼Œå¹¶ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†
    masks: list of dicts or list of strings
    model_ids: list of str
    """
    print(">>> overlay received masks =", masks)
    # ===== âœ… å…³é”®ä¿®å¤ï¼šä¿è¯ masks æ˜¯ list =====
    if isinstance(masks, (str, dict)):
        masks = [masks]

    print(">>> overlay received masks =", masks)
    base_img = cv2.imread(base_image_path)
    if base_img is None:
        raise FileNotFoundError(f"æ— æ³•è¯»å–åº•å›¾: {base_image_path}")

    overlay = base_img.copy()
    print(model_ids)
    model_ids = model_ids['selected_models']
    print(model_ids)
    for mask, model_id in zip(masks, model_ids):
        model_id_lower = model_id.lower()

        # ---------- é¢œè‰²ç­–ç•¥ ----------
        if "fracture" in model_id_lower:
            color = (0, 0, 255)        # ğŸ”´ è£‚ç¼
        elif "vug" in model_id_lower:
            color = (0, 255, 255)      # ğŸŸ¡ å­”æ´
        elif "sam2" in model_id_lower:
            color = (0, 255, 0)        # ğŸŸ¢ SAM2
        else:
            color = (255, 255, 255)    # âšª å…œåº•

        # ---------- è¯»å– mask ----------
        if isinstance(mask, dict):
            mask_path = mask.get("mask")
        elif isinstance(mask, str):
            mask_path = mask
        else:
            if log_fn:
                log_fn(f"âš ï¸ overlay_masks è·³è¿‡æœªçŸ¥ç±»å‹: {type(mask)}")
            continue

        if not mask_path or not os.path.exists(mask_path):
            if log_fn:
                log_fn(f"âš ï¸ mask ä¸å­˜åœ¨: {mask_path}")
            continue

        mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        print(f"ğŸ§© mask_img.shape = {mask_img.shape}, dtype = {mask_img.dtype}")
        if mask_img is None:
            continue

        # ---------- äºŒå€¼åŒ– ----------
        _, binary = cv2.threshold(mask_img, 1, 255, cv2.THRESH_BINARY)

        # ---------- æå–è½®å»“ ----------
        contours, _ = cv2.findContours(
            binary,
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )

        # ---------- ç»˜åˆ¶ï¼ˆå¡«å……ï¼‰ ----------
        cv2.drawContours(
            overlay,
            contours,
            -1,
            color,
            thickness=cv2.FILLED
        )

    out_path = base_image_path.replace(".png", "_overlay.png")
    cv2.imwrite(out_path, overlay)
    print(out_path)
    return out_path
def overlay_masks(masks, model_ids, base_image_path, log_fn=None):
    """
    å°† U-Netï¼ˆè£‚ç¼ / å­”æ´ï¼‰+ SAM2 çš„æ©ç å åŠ åˆ°åŸå›¾ä¸Šï¼Œå¹¶ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†
    masks: list of dicts or list of strings
    model_ids: list of str æˆ– dict åŒ…å« selected_models
    """
    print(">>> overlay received masks =", masks)
    import os, cv2

    # ===== âœ… å…³é”®ä¿®å¤ï¼šä¿è¯ masks æ˜¯ list =====
    if isinstance(masks, (str, dict)):
        masks = [masks]

    base_img = cv2.imread(base_image_path)
    if base_img is None:
        raise FileNotFoundError(f"æ— æ³•è¯»å–åº•å›¾: {base_image_path}")

    overlay = base_img.copy()

    # ===== å¤„ç† model_ids =====
    if isinstance(model_ids, dict) and 'selected_models' in model_ids:
        model_ids = model_ids['selected_models']
    if not isinstance(model_ids, list):
        model_ids = []

    # ===== éå† masksï¼Œä¸å†ç”¨ zipï¼Œè€Œæ˜¯å•ç‹¬åŒ¹é…é¢œè‰² =====
    for mask in masks:
        # ---------- è¯»å– mask_path ----------
        if isinstance(mask, dict):
            mask_path = mask.get("mask")
        elif isinstance(mask, str):
            mask_path = mask
        else:
            if log_fn:
                log_fn(f"âš ï¸ overlay_masks è·³è¿‡æœªçŸ¥ç±»å‹: {type(mask)}")
            continue

        if not mask_path or not os.path.exists(mask_path):
            if log_fn:
                log_fn(f"âš ï¸ mask ä¸å­˜åœ¨: {mask_path}")
            continue

        # ---------- æ ¹æ®æ–‡ä»¶åæˆ–ç±»å‹åŒ¹é…é¢œè‰² ----------
        color = (255, 255, 255)  # é»˜è®¤ç™½è‰²
        lower_path = mask_path.lower()
        if "full_mask" in lower_path:
            color = (0, 0, 255)        # ğŸ”´ è£‚ç¼
        elif "full_mask_vug" in lower_path:
            color = (0, 255, 255)      # ğŸŸ¡ å­”æ´
        else:
            # å°è¯•ç”¨ model_ids åŒ¹é…
            for mid in model_ids:
                mid_lower = mid.lower()
                if "fracture" in mid_lower:
                    color = (0, 0, 255)
                    break
                elif "vug" in mid_lower:
                    color = (0, 255, 255)
                    break
                elif "sam2" in mid_lower:
                    color = (0, 255, 0)
                    break

        mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask_img is None:
            continue

        # ---------- äºŒå€¼åŒ– ----------
        _, binary = cv2.threshold(mask_img, 1, 255, cv2.THRESH_BINARY)

        # ---------- æå–è½®å»“ ----------
        contours, _ = cv2.findContours(
            binary,
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )

        # ---------- ç»˜åˆ¶ï¼ˆå¡«å……ï¼‰ ----------
        cv2.drawContours(
            overlay,
            contours,
            -1,
            color,
            thickness=cv2.FILLED
        )

    # ===== è¾“å‡ºç»“æœè·¯å¾„ =====
    out_path = base_image_path.replace(".png", "_overlay.png")
    cv2.imwrite(out_path, overlay)
    if log_fn:
        log_fn(f"âœ… Overlay saved: {out_path}")

    return out_path
def visualize_pipeline(
    image_path,
    sliding_results,
    unet_results,
    yolo_results,
    model_ids,
    image_height_px,
    log_fn=None
):
    """
    å¯è§†åŒ–æ€»è°ƒåº¦å‡½æ•°
    é¡ºåºï¼š
    1. æå–è£‚ç¼/å­”æ´ mask
    2. å åŠ  overlay
    3. ç»˜åˆ¶æœ€ç»ˆæ£€æµ‹ + æ›²çº¿
    """

    if log_fn:
        log_fn("ğŸš€ Start visualization pipeline")

    # ========= Step 1: æå– mask =========
    overlay_dict = extract_overlay_masks(
        sliding_results,
        log_fn=log_fn
    )

    masks = [
        overlay_dict.get("derived.overlay.fracture_mask"),
        overlay_dict.get("derived.overlay.vug_mask")
    ]

    # è¿‡æ»¤ None
    masks = [m for m in masks if m]

    if log_fn:
        log_fn(f"ğŸŸ¢ Masks extracted: {masks}")

    # ========= Step 2: å åŠ  overlay =========
    overlay_path = None
    if masks:
        overlay_path = overlay_masks(
            masks,
            model_ids,
            image_path,
            log_fn=log_fn
        )
    else:
        overlay_path = image_path
        if log_fn:
            log_fn("âš ï¸ No masks found, skip overlay")

    # ========= Step 3: ç»˜åˆ¶æœ€ç»ˆç»“æœ =========
    final_path = draw_final_results(
        overlay_path,
        unet_results,
        yolo_results,
        image_height_px
    )

    if log_fn:
        log_fn(f"âœ… Visualization done: {final_path}")

    return {
        "overlay_image": overlay_path,
        "final_image": final_path
    }
#å››ã€è£‚ç¼ / å­”æ´å‚æ•°åˆ†ææ¥å£
# ===== è£‚ç¼åˆ†æ API =====
def call_crack_api(mask_path, image_height_mm, image_width_mm):
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    binary_mask = (mask_img > 0).astype(np.uint8) * 255
    temp_mask_path = f"temp_mask_{uuid.uuid4().hex}.png"
    #temp_mask_path = os.path.join(temp_dir, f"temp_mask_{uuid.uuid4().hex}.png")
    cv2.imwrite(temp_mask_path, binary_mask)
    with open(temp_mask_path, "rb") as f:
        files = {"file": (temp_mask_path, f, "image/png")}
        data = {
            "image_height_mm": str(image_height_mm),
            "image_width_mm": str(image_width_mm)
        }
        resp = requests.post("http://127.0.0.1:8010/analyze_crack", files=files, data=data)
        if resp.status_code != 200:
            raise RuntimeError(f"è£‚ç¼åˆ†æå¤±è´¥: {resp.text}")
        result = resp.json()
    # è¡¥å…¨å­—æ®µ
    required_keys = ["A", "B", "C", "D", "å€¾è§’_deg", "å€¾å‘_deg", "èµ°å‘_deg",
                     "è£‚ç¼å®½åº¦_FVA", "è£‚ç¼é•¿åº¦_FVTL", "è£‚ç¼å¯†åº¦_FVDC", "è£‚ç¼è§†å­”éš™åº¦_FVPA"]
    for k in required_keys:
        if k not in result:
            result[k] = None
    return result

def call_vug_api(image_path, image_height_mm, image_width_mm, window_height_mm):
    with open(image_path, "rb") as f:
        files = {"file": (image_path, f, "image/png")}
        data = {
            "image_height_mm": str(image_height_mm),
            "image_width_mm": str(image_width_mm),
            "window_height_mm": str(window_height_mm)
        }
        resp = requests.post("http://127.0.0.1:8011/analyze_vug", files=files, data=data)
        if resp.status_code != 200:
            raise RuntimeError(f"å­”æ´åˆ†æå¤±è´¥: {resp.text}")
        return resp.json()
#äº”ã€æ»‘çª—åˆ†æï¼ˆæ ¸å¿ƒè®¡ç®—æ¨¡å—ï¼‰
# ===== æ»‘çª—åˆ†æ =====
# ===== æ»‘çª—åˆ†æï¼ˆæ€»æ§è°ƒåº¦å™¨ï¼‰=====
def sliding_window_analysis(
    image_path,
    model_ids,
    model_parameters,
    log_fn=None
):
    """
    æ€»æ§æ»‘çª—åˆ†æå‡½æ•°
    - æ ¹æ® model_id ç±»å‹è‡ªåŠ¨åˆ†æ´¾ fracture / vug
    - ç»Ÿä¸€å‚æ•°å…¥å£ model_parameters
    - ç»Ÿä¸€ç»“æ„åŒ–è¿”å›ç»“æœ
    """

    results = {
        "fracture": [],
        "vug": []
    }

    # ---- åŸºç¡€å‚æ•°æ ¡éªŒï¼ˆå·¥ç¨‹å¿…å¤‡ï¼‰----
    required_base_keys = ["image_height_mm", "image_width_mm"]
    for k in required_base_keys:
        if k not in model_parameters:
            raise KeyError(f"model_parameters ç¼ºå°‘å¿…è¦å‚æ•°: {k}")
    #print(model_ids)
    print(type(model_ids))
    model_list = model_ids['model_ids']
    print(model_list)
    print(type(model_list))
    # âœ… å…¼å®¹ Executor è¯¯ä¼  dict çš„æƒ…å†µ
    for model_id in model_list:

        model_id_lower = model_id.lower()

        # ===== è£‚ç¼æ¨¡å‹ =====
        if "unet_fracture" in model_id_lower:

            if log_fn:
                log_fn(f"ğŸ§© å¯åŠ¨è£‚ç¼æ»‘çª—åˆ†æ: {model_id}")

            out = sliding_window_unet_analysis(
                image_path=image_path,
                model_id=model_id,
                image_height_mm=model_parameters["image_height_mm"],
                image_width_mm=model_parameters["image_width_mm"],
                log_fn=log_fn
            )

            results["fracture"].append({
                "model_id": model_id,
                "mask": out.get("fracture_mask"),
                "metrics": out.get("fracture_metrics", [])
            })

        # ===== å­”æ´æ¨¡å‹ =====
        elif "unet_vug" in model_id_lower:

            if log_fn:
                log_fn(f"ğŸ§© å¯åŠ¨å­”æ´æ»‘çª—åˆ†æ: {model_id}")

            mask_path, window_metrics, summary = sliding_window_vug_analysis(
                image_path=image_path,
                model_id=model_id,
                image_height_mm=model_parameters["image_height_mm"],
                image_width_mm=model_parameters["image_width_mm"],
                window_height_mm=model_parameters.get("window_height_mm", 1000),
                window_px=model_parameters.get("window_px"),
                log_fn=log_fn
            )

            results["vug"].append({
                "model_id": model_id,
                "mask": mask_path,
                "window_metrics": window_metrics,
                "summary": summary
            })

        else:
            if log_fn:
                log_fn(f"âš ï¸ æœªè¯†åˆ«çš„æ¨¡å‹ç±»å‹ï¼Œå·²è·³è¿‡: {model_id}")
    # ---------- æ‰“å° mask_path ä¿¡æ¯ ----------
    print("ğŸ§© Fracture masks:")
    for f in results["fracture"]:
        print(f"- model_id: {f['model_id']}, mask_path: {f.get('mask')}")

    print("ğŸŸ¡ Vug masks:")
    for v in results["vug"]:
        print(f"- model_id: {v['model_id']}, mask_path: {v.get('mask')}")

    return results

def sliding_window_unet_analysis(image_path, model_id, image_height_mm, image_width_mm, log_fn=None):
    img = cv2.imread(image_path)
    H, W = img.shape[:2]
    window_px = W  # å¯ä»¥è‡ªå®šä¹‰æ»‘çª—é«˜åº¦
    n_blocks = math.ceil(H / window_px)
    masks_full = np.zeros((H, W), dtype=np.uint8)
    curves_metrics_all = []

    for i in range(n_blocks):
        start_y = i * window_px
        end_y = min((i+1) * window_px, H)
        img_block = img[start_y:end_y, :]
        block_path = f"temp_block_{uuid.uuid4().hex}.png"
        #block_path = os.path.join(temp_dir, f"temp_block_{uuid.uuid4().hex}.png")
        cv2.imwrite(block_path, img_block)

        try:
            mask_result = call_unet_api(model_id, block_path)
            mask_block = cv2.imread(mask_result["mask"], cv2.IMREAD_GRAYSCALE)
            if mask_block is None:
                continue
            masks_full[start_y:end_y, :] = np.maximum(masks_full[start_y:end_y, :], mask_block)

            # è£‚ç¼åˆ†æ
            mask_path = preprocess_mask_for_analysis(mask_result["mask"], log_fn)
            single_masks = split_mask_to_contours(mask_path)
            for j, mask_single in enumerate(single_masks):
                temp_mask_path = f"temp_single_block_{i}_{j}.png"
                #temp_mask_path = os.path.join(temp_dir, f"temp_single_block_{i}_{j}.png")
                cv2.imwrite(temp_mask_path, mask_single)
                metrics = call_crack_api(temp_mask_path, image_height_mm, image_width_mm)
                metrics["y_offset"] = start_y  # âš¡ æ·»åŠ å—åç§»
                curves_metrics_all.append(metrics)

        except Exception as e:
            if log_fn:
                log_fn(f"âŒ åˆ†å— U-Net åˆ†æå¤±è´¥: {e}")

    mask_full_path = f"full_mask_{uuid.uuid4().hex}.png"
    #mask_full_path = os.path.join(temp_dir, f"full_mask_{uuid.uuid4().hex}.png")
    # âœ… å¼ºåˆ¶å½’ä¸€åŒ–ä¸º 0-255ï¼Œä¿è¯æ˜¾ç¤ºæ•ˆæœä¸ SAM2 ä¸€è‡´
    if masks_full.max() <= 1:
        masks_full = (masks_full * 255).astype(np.uint8)
    else:
        masks_full = masks_full.astype(np.uint8)

    cv2.imwrite(mask_full_path, masks_full)
    # âœ…ã€å…³é”®ä¿®æ”¹ã€‘â€”â€” è¿”å› dictï¼Œä¸¥æ ¼åŒ¹é… plan.outputs
    fracture_metrics_filtered = [m for m in curves_metrics_all if
                                 all(k in m and m[k] is not None for k in ["A", "B", "C", "D"])]
    print(mask_full_path)
    return {
        "fracture_mask": mask_full_path,
        "fracture_metrics": fracture_metrics_filtered
    }

def sliding_window_vug_analysis(
    image_path,
    model_id,
    image_height_mm,
    image_width_mm,
    window_height_mm=1000,   # é»˜è®¤ 1 m
    window_px=None,          # âœ… æ”¯æŒæ˜¾å¼åƒç´ æ»‘çª—
    log_fn=None
):
    """
    å­”æ´ç»Ÿä¸€åˆ†ææµç¨‹ï¼ˆä¸è£‚ç¼æ»‘çª—ä¿æŒä¸€è‡´ï¼‰ï¼š
    - å†…éƒ¨æ»‘çª—ï¼šåƒç´ 
    - ç»Ÿè®¡å•ä½ï¼šmm
    - è¿”å›ï¼šmask_full_path, window_metrics, summary
    """

    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {image_path}")

    H, W = img.shape[:2]

    # ===== px â†” mm æ˜ å°„ =====
    px_per_mm = H / image_height_mm
    mm_per_px = image_height_mm / H

    # ===== æ»‘çª—ä¼˜å…ˆçº§ï¼šwindow_px > window_height_mm =====
    if window_px is not None:
        window_px = int(window_px)
        window_height_mm = window_px * mm_per_px
    else:
        window_px = int(window_height_mm * px_per_mm)

    window_px = max(1, window_px)
    n_blocks = math.ceil(H / window_px)

    masks_full = np.zeros((H, W), dtype=np.uint8)

    window_vug_list = []
    total_vug_count = 0
    total_area_mm2 = 0
    all_CVPA, all_CDENS, all_CSIZE = [], [], []

    for i in range(n_blocks):
        start_y = i * window_px
        end_y = min(start_y + window_px, H)

        depth_start_mm = start_y * mm_per_px
        depth_end_mm = end_y * mm_per_px
        window_depth_mm = depth_end_mm - depth_start_mm

        img_block = img[start_y:end_y, :]
        block_path = f"temp_vug_block_{uuid.uuid4().hex}.png"
        cv2.imwrite(block_path, img_block)

        try:
            # ---------- â‘  U-Net å­”æ´åˆ†å‰² ----------
            mask_result = call_unet_api(model_id, block_path)
            mask_block = cv2.imread(mask_result["mask"], cv2.IMREAD_GRAYSCALE)
            if mask_block is None:
                continue

            masks_full[start_y:end_y, :] = np.maximum(
                masks_full[start_y:end_y, :],
                mask_block
            )

            # ---------- â‘¡ å•æ»‘çª—å­”æ´ç»Ÿè®¡ ----------
            cleaned_mask = preprocess_mask_for_analysis(mask_result["mask"], log_fn)

            result = call_vug_api(
                cleaned_mask,
                image_height_mm=window_depth_mm,
                image_width_mm=image_width_mm,
                window_height_mm=window_depth_mm
            )

            summary = result.get("summary", {})
            vugs = result.get("vugs", [])

            window_info = {
                "depth_start_mm": round(depth_start_mm, 2),
                "depth_end_mm": round(depth_end_mm, 2),
                "vug_count": summary.get("vug_count", 0),
                "total_area_mm2": summary.get("total_area_mm2", 0),
                "CVPA": summary.get("CVPA", 0),
                "CDENS": summary.get("CDENS", 0),
                "CSIZE": summary.get("CSIZE", 0),
                "vugs": vugs
            }

            window_vug_list.append(window_info)

            total_vug_count += window_info["vug_count"]
            total_area_mm2 += window_info["total_area_mm2"]
            all_CVPA.append(window_info["CVPA"])
            all_CDENS.append(window_info["CDENS"])
            all_CSIZE.append(window_info["CSIZE"])

            if log_fn:
                log_fn(f"âœ… å­”æ´æ»‘çª— {i+1}/{n_blocks} å®Œæˆ")

        except Exception as e:
            if log_fn:
                log_fn(f"âš ï¸ åˆ†å—å­”æ´åˆ†æå¤±è´¥: {e}")

    # ---------- ä¿å­˜æ•´å›¾ mask ----------
    mask_full_path = f"full_mask_vug_{uuid.uuid4().hex}.png"
    if masks_full.max() <= 1:
        masks_full = (masks_full * 255).astype(np.uint8)
    else:
        masks_full = masks_full.astype(np.uint8)
    cv2.imwrite(mask_full_path, masks_full)

    # ---------- æ•´äº•æ±‡æ€» ----------
    summary_metrics = {
        "total_vug_count": total_vug_count,
        "total_area_mm2": total_area_mm2,
        "mean_CVPA": np.mean(all_CVPA) if all_CVPA else 0,
        "mean_CDENS": np.mean(all_CDENS) if all_CDENS else 0,
        "mean_CSIZE": np.mean(all_CSIZE) if all_CSIZE else 0
    }

    if log_fn:
        log_fn(
            f"ğŸ“Š å­”æ´æ»‘çª—åˆ†æå®Œæˆ: "
            f"æ€»å­”æ´æ•°={total_vug_count}, æ€»é¢ç§¯={total_area_mm2:.2f} mmÂ²"
        )
    print(mask_full_path)
    return mask_full_path, window_vug_list, summary_metrics




# ===== SAM2 æ»‘çª—åˆ†æ =====
def sliding_window_sam2_analysis(image_path, image_height_mm, image_width_mm, log_fn=None):
    """
    æ»‘çª—è°ƒç”¨ SAM2ï¼ˆprompt_free æ¨¡å¼ï¼‰ï¼Œå¹¶æ‹¼æ¥æ•´ä½“æ©ç 
    """
    img = cv2.imread(image_path)
    H, W = img.shape[:2]
    window_px = W  # ä¸ U-Net ä¸€è‡´ï¼Œçºµå‘æ»‘çª—
    n_blocks = math.ceil(H / window_px)
    masks_full = np.zeros((H, W), dtype=np.uint8)
    curves_metrics_all = []

    for i in range(n_blocks):
        start_y = i * window_px
        end_y = min((i + 1) * window_px, H)
        img_block = img[start_y:end_y, :]
        block_path = f"temp_sam2_block_{uuid.uuid4().hex}.png"
        cv2.imwrite(block_path, img_block)

        try:
            # prompt_free æ¨¡å¼åˆ†å‰²
            sam2_result = call_sam2_api(block_path, prompt_type="prompt_free")
            mask_b64 = sam2_result.get("mask", None)
            if not mask_b64:
                if log_fn:
                    log_fn(f"âš ï¸ SAM2 ç¬¬ {i+1}/{n_blocks} å—æœªè¿”å›æœ‰æ•ˆ mask")
                continue

            mask_bytes = base64.b64decode(mask_b64)
            mask_block_path = f"sam2_block_mask_{uuid.uuid4().hex}.png"
            #mask_block_path = os.path.join(temp_dir, f"sam2_block_mask_{uuid.uuid4().hex}.png")
            with open(mask_block_path, "wb") as f:
                f.write(mask_bytes)

            mask_block = cv2.imread(mask_block_path, cv2.IMREAD_GRAYSCALE)
            if mask_block is None:
                continue

            masks_full[start_y:end_y, :] = np.maximum(
                masks_full[start_y:end_y, :], mask_block
            )

            # è£‚ç¼å‚æ•°åˆ†æï¼ˆåŒ U-Netï¼‰
            mask_path = preprocess_mask_for_analysis(mask_block_path, log_fn)
            single_masks = split_mask_to_contours(mask_path)
            for j, mask_single in enumerate(single_masks):
                temp_mask_path = f"temp_single_sam2_block_{i}_{j}.png"
                #temp_mask_path = os.path.join(temp_dir, f"temp_single_sam2_block_{i}_{j}.png")
                cv2.imwrite(temp_mask_path, mask_single)
                metrics = call_crack_api(temp_mask_path, image_height_mm, image_width_mm)
                metrics["y_offset"] = start_y
                curves_metrics_all.append(metrics)

            if log_fn:
                log_fn(f"âœ… SAM2 æ»‘çª—å— {i+1}/{n_blocks} åˆ†æå®Œæˆï¼Œè£‚ç¼ {len(single_masks)} æ¡")

        except Exception as e:
            if log_fn:
                log_fn(f"âŒ SAM2 æ»‘çª—å— {i+1}/{n_blocks} å¤±è´¥: {e}")

    mask_full_path = f"full_sam2_mask_{uuid.uuid4().hex}.png"
    #mask_full_path = os.path.join(temp_dir, f"full_sam2_mask_{uuid.uuid4().hex}.png")
    cv2.imwrite(mask_full_path, masks_full)
    return mask_full_path, curves_metrics_all
#å…­ã€ç»“æœå¯è§†åŒ–ä¸ç»˜åˆ¶
# ===== ç»˜åˆ¶æœ€ç»ˆç»“æœï¼ˆä¿æŒä¸å˜ï¼Œä½¿ç”¨ metrics["y_offset"]ï¼‰ =====
# ========== ç»˜åˆ¶èŒèšªå›¾ (æ”¹è¿›ç‰ˆ) ==========

def extract_masks_from_sliding_results(sliding_results, target_classes=None, log_fn=None):
    """
    ä» sliding_results ä¸­æå– mask è·¯å¾„
    - sliding_results: {"fracture": [...], "vug": [...]}
    - target_classes: ["fracture", "vug"] é»˜è®¤æå–å…¨éƒ¨
    è¿”å›: list of dicts {"mask": mask_path}, list of model_ids
    """
    if target_classes is None:
        target_classes = sliding_results.keys()

    masks_list = []
    model_ids = []

    for cls in target_classes:
        items = sliding_results.get(cls, [])
        for item in items:
            mask_path = item.get("mask") or item.get("mask_path")  # å…¼å®¹ fracture/vug
            if not mask_path:
                if log_fn:
                    log_fn(f"âš ï¸ {cls} æ¡ç›®ç¼ºå°‘ mask è·¯å¾„: {item}")
                continue
            masks_list.append({"mask": mask_path})
            model_ids.append(f"unet_{cls}")

    return masks_list, model_ids



def plot_tadpole_from_crack_results_v2(valid_curves,
                                   save_path="tadpole.png",
                                   image_height_px=1422,
                                   image_width_px=472,
                                   dpi=100,
                                   start_depth=1170000,
                                   end_depth=1172500):
    """
    èŒèšªå›¾ç»˜åˆ¶ï¼ˆç›´æ¥åƒç´ åæ ‡ç»˜åˆ¶ + æ·±åº¦åˆ»åº¦æ˜¾ç¤ºï¼‰

    å‚æ•°ï¼š
    - valid_curves: list[dict]ï¼Œæ¯é¡¹åŒ…å« "D", "y_offset", "å€¾è§’_deg", "å€¾å‘_deg"
    - save_path: è¾“å‡ºè·¯å¾„
    - image_height_px, image_width_px: å›¾åƒåƒç´ å°ºå¯¸
    - dpi: åˆ†è¾¨ç‡
    - start_depth, end_depth: yè½´æ˜¾ç¤ºæ·±åº¦èŒƒå›´
    """
    if not valid_curves:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆæ›²çº¿æ•°æ®ï¼Œæ— æ³•ç”ŸæˆèŒèšªå›¾")

    # ==== å›¾åƒå°ºå¯¸ ====
    fig_w_in = image_width_px / dpi
    fig_h_in = image_height_px / dpi
    fig, ax = plt.subplots(figsize=(fig_w_in, fig_h_in), dpi=dpi)

    # ==== åæ ‡è½´è®¾ç½® ====
    ax.set_xlim(0, 90)               # å€¾è§’èŒƒå›´
    ax.set_ylim(image_height_px, 0)  # ä¸Šæµ…ä¸‹æ·±
    ax.set_xlabel("Dip Angle (Â°)", fontsize=9)
    ax.set_ylabel("Depth (mm)", fontsize=9)

    # yè½´åˆ»åº¦æ˜¾ç¤ºæ·±åº¦
    def depth_formatter(y_px, pos):
        return f"{start_depth + (y_px / image_height_px) * (end_depth - start_depth):.0f}"
    ax.yaxis.set_major_formatter(FuncFormatter(depth_formatter))
    ax.xaxis.set_ticks_position("top")
    ax.xaxis.set_label_position("top")
    ax.grid(alpha=0.3)

    # ==== ç»˜åˆ¶èŒèšª ====
    cmap = plt.get_cmap("tab10")
    tail_len_px = 40  # å°¾å·´é•¿åº¦ï¼ˆåƒç´ ï¼‰

    print("çºµå‘ä½ç½®(y_offset, D):", [(m.get("y_offset",0), m.get("D",0)) for m in valid_curves])

    for i, m in enumerate(valid_curves):
        dip = m.get("å€¾è§’_deg", 0)
        az = m.get("å€¾å‘_deg", 0)
        y_px = m.get("y_offset", 0) + m.get("D", 0)
        color = cmap(i % 10)

        # å¤´éƒ¨
        ax.scatter(dip, y_px, color=color, s=30, zorder=3)

        # å°¾å·´æ–¹å‘
        dx = tail_len_px * np.sin(np.deg2rad(az))
        dy = tail_len_px * np.cos(np.deg2rad(az))
        ax.arrow(dip, y_px, dx/90*10, dy, color=color, alpha=0.8,
                 width=0.5, head_width=2.5, length_includes_head=True)

    plt.subplots_adjust(left=0.2, right=0.95, top=0.92, bottom=0.08)
    fig.savefig(save_path, dpi=dpi)
    plt.close(fig)
    print(f"âœ… èŒèšªå›¾ä¿å­˜: {save_path} ({image_width_px}Ã—{image_height_px}px)")

def create_tadpole_overlay(valid_curves,
                           overlay_img_path="temp_input_overlay_final.png",
                           save_path="tadpole_overlay.png",
                           dpi=100,
                           depth_start=1170000,
                           depth_end=1172500,
                           tail_len_px=40):
    """
    ç»˜åˆ¶èŒèšªå›¾å¹¶ä¸åŸå§‹å›¾æ¨ªå‘æ‹¼æ¥ï¼Œå·¦ä¾§æ·»åŠ æ·±åº¦é“ã€‚

    å‚æ•°ï¼š
    - valid_curves: list[dict] åŒ…å« "D", "y_offset", "å€¾è§’_deg", "å€¾å‘_deg"
    - overlay_img_path: åŸå§‹å›¾è·¯å¾„
    - save_path: è¾“å‡ºè·¯å¾„
    - dpi: åˆ†è¾¨ç‡
    - depth_start, depth_end: yè½´æ·±åº¦èŒƒå›´
    - tail_len_px: èŒèšªå°¾å·´é•¿åº¦
    """
    # === è¯»å–åŸå›¾ ===
    base_img = cv2.imread(overlay_img_path)
    img_h, img_w = base_img.shape[:2]

    # === èŒèšªå›¾ç»˜åˆ¶ ===
    fig, ax = plt.subplots(figsize=(img_w/dpi, img_h/dpi), dpi=dpi)

    ax.set_xlim(0, 90)
    ax.set_ylim(img_h, 0)  # ä¸Šæµ…ä¸‹æ·±
    ax.axis('off')  # å»æ‰å¤šä½™åæ ‡

    cmap = plt.get_cmap("tab10")
    for i, m in enumerate(valid_curves):
        dip = m.get("å€¾è§’_deg", 0)
        az = m.get("å€¾å‘_deg", 0)
        y_px = m.get("y_offset", 0) + m.get("D", 0)
        color = cmap(i % 10)
        ax.scatter(dip, y_px, color=color, s=30, zorder=3)
        dx = tail_len_px * np.sin(np.deg2rad(az))
        dy = tail_len_px * np.cos(np.deg2rad(az))
        ax.arrow(dip, y_px, dx/90*10, dy, color=color, alpha=0.8,
                 width=0.5, head_width=2.5, length_includes_head=True)

    fig.tight_layout(pad=0)
    fig.canvas.draw()

    # å°†ç»˜å›¾ä¿å­˜åˆ° numpy æ•°ç»„
    tadpole_img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    tadpole_img = tadpole_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))
    plt.close(fig)

    # === æ·»åŠ æ·±åº¦é“ ===
    depth_width = 60
    depth_img = np.zeros((img_h, depth_width, 3), dtype=np.uint8) + 255  # ç™½è‰²èƒŒæ™¯
    n_ticks = 10
    for i in range(n_ticks+1):
        y = int(i * img_h / n_ticks)
        depth_val = int(depth_start + (y/img_h)*(depth_end-depth_start))
        cv2.putText(depth_img, f"{depth_val}", (2, y+5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 1, cv2.LINE_AA)

    # === æ¨ªå‘æ‹¼æ¥ï¼šæ·±åº¦é“ + åŸå›¾ + èŒèšªå›¾ ===
    tadpole_img_resized = cv2.resize(tadpole_img, (img_w, img_h))
    final_img = np.hstack([depth_img, base_img, tadpole_img_resized])

    # === ä¿å­˜ ===
    cv2.imwrite(save_path, final_img)
    print(f"âœ… æ‹¼æ¥èŒèšªå›¾ä¿å­˜: {save_path}")
def draw_final_results(base_image_path, unet_results, yolo_results, H):
    base_img = Image.open(base_image_path).convert("RGB")
    img_np = np.array(base_img)
    draw = ImageDraw.Draw(base_img)

    # ---------- YOLO æ¡† ----------
    if isinstance(yolo_results, dict):
        detections = yolo_results.get("detections", [])
    else:
        detections = []  # å¦‚æœä¸æ˜¯ dictï¼Œå°±å¿½ç•¥
    for det in detections:
        cls = det.get("class", "")
        conf = det.get("confidence", 0)
        bbox = list(map(int, det.get("bbox", [])))
        draw.rectangle(bbox, outline="red", width=2)
        draw.text((bbox[0], max(0, bbox[1]-12)), f"{cls} {conf:.2f}", fill="red")

    # ---------- U-Net / SAM2 æ©ç  + è£‚ç¼æ›²çº¿ ----------
    if isinstance(unet_results, dict):
        items = []
        for v in unet_results.values():
            if isinstance(v, list):
                items.extend(v)
        unet_results = items
    elif not isinstance(unet_results, list):
        unet_results = []

    for item in unet_results:
        if not isinstance(item, dict):
            continue  # è·³è¿‡é dict
        cls = str(item.get("class", "")).lower()
        print("ğŸ§¬ drawing item class =", cls)
        mask_entry = item.get("mask_result")
        if isinstance(mask_entry, dict):
            mask_path = mask_entry.get("mask")
        elif isinstance(mask_entry, str):
            mask_path = mask_entry
        else:
            mask_path = None

        if not mask_path or not os.path.exists(mask_path):
            continue

        mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask_img is None:
            continue

        # ---------- æ©ç è½®å»“ ----------
        contours, _ = cv2.findContours((mask_img>0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            pts = [tuple(pt[0]) for pt in contour]
            draw.line(pts, fill=(0, 255, 0), width=2)

        # ---------- è£‚ç¼æ›²çº¿ ----------
        if cls == "fracture":
            metrics_list = item.get("metrics_list", [])
            print(metrics_list)
            print("ğŸ“ metrics_list length =", len(metrics_list))
            if not isinstance(metrics_list, list):
                continue
            for metrics in metrics_list:
                if all(k in metrics for k in ["A", "B", "C", "D"]):
                    A = metrics["A"]
                    B = metrics["B"]
                    C = metrics["C"]
                    D = metrics["D"]
                    y_offset = metrics.get("y_offset", 0)
                    if None not in [A, B, C, D]:
                        w = img_np.shape[1]
                        x_fit = np.arange(w)
                        y_fit = A * np.sin(B * x_fit + C) + D + y_offset
                        points = [(int(x), int(y)) for x, y in zip(x_fit, y_fit) if 0 <= int(y) < H]
                        print(
                            f"ğŸ“ˆ curve y range = [{np.min(y_fit):.1f}, {np.max(y_fit):.1f}], H = {H}"
                        )
                        draw.line([(0, H // 2), (img_np.shape[1], H // 2)], fill=(255, 0, 0), width=3)
                        for i in range(len(points)-1):
                            draw.line([points[i], points[i+1]], fill=(0, 0, 0), width=2)

    out_path = base_image_path.replace(".png","_final.png")
    base_img.save(out_path)
    print(out_path)
    return out_path

# è®°å½•
def record_execution_state(
    intent: str = "",
    planner: Dict[str, Any] = None,
    flags: Dict[str, Any] = None,
    raw_sliding: Any = None,
    refined_curves: Any = None,
    analysis_log: Any = None,
    extra: Dict[str, Any] = None,
    output_dir: str = "records",
    prefix: str = "execution_record"
):
    """
    ğŸ“Œ Recorder Tool

    Parameters
    ----------
    intent : str
        Planner intent or task description
    planner : dict
        Planner-related outputs (selected_models, parameters, etc.)
    flags : dict
        Runtime flags (enable_sam2, enable_reflection, etc.)
    raw_sliding : any
        Raw sliding_window_analysis results
    refined_curves : any
        Post-reflection curves (if exists)
    analysis_log : any
        DeepSeek reflection logs
    extra : dict
        Any additional user-defined content
    output_dir : str
        Directory to store records
    prefix : str
        Filename prefix

    Returns
    -------
    dict
        {
            "record_path": "...",
            "record_id": "...",
            "timestamp": "..."
        }
    """

    os.makedirs(output_dir, exist_ok=True)

    record_id = uuid.uuid4().hex
    timestamp = datetime.datetime.now().isoformat()

    record = {
        "record_id": record_id,
        "timestamp": timestamp,
        "intent": intent,
        "planner": planner or {},
        "flags": flags or {},
        "raw_sliding_results": raw_sliding,
        "refined_curves": refined_curves,
        "analysis_log": analysis_log,
        "extra": extra or {}
    }

    record_path = os.path.join(
        output_dir,
        f"{prefix}_{record_id}.json"
    )

    with open(record_path, "w", encoding="utf-8") as f:
        json.dump(record, f, indent=2, ensure_ascii=False)

    return {
        "record_path": record_path,
        "record_id": record_id,
        "timestamp": timestamp
    }
# æ´¾ç”Ÿå˜é‡
def generate_x_points(curves_metrics, image_width_px):
    """
    Generate x_points for each curve.
    """
    if curves_metrics is None:
        return []
    valid_curves = [m for m in curves_metrics if all(
        k in m and m[k] is not None for k in ["A", "B", "C", "D"]
    )]
    x_points_list = []
    x_points_list=[np.arange(image_width_px) for _ in valid_curves]
    return x_points_list
def extract_fracture_metrics(sliding_results: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Extract and flatten fracture metrics from sliding_results.

    Returns:
        metrics_list: List[dict]
            Each dict corresponds to ONE fracture curve, with metadata.
    """

    if not isinstance(sliding_results, dict):
        raise ValueError("sliding_results must be a dict")

    fracture_blocks = sliding_results.get("fracture", [])
    if not fracture_blocks:
        return []

    metrics_list: List[Dict[str, Any]] = []

    for block_idx, block in enumerate(fracture_blocks):

        if not isinstance(block, dict):
            continue

        model_id = block.get("model_id", "unknown")
        metrics = block.get("metrics", [])

        # metrics æœ¬èº«æ˜¯ list
        if not isinstance(metrics, list):
            continue

        for curve_idx, curve_metrics in enumerate(metrics):
            if not isinstance(curve_metrics, dict):
                continue

            # âœ… å¤åˆ¶ä¸€ä»½ï¼Œé¿å…åŸåœ°æ±¡æŸ“
            item = dict(curve_metrics)

            # âœ… æ³¨å…¥å…ƒä¿¡æ¯ï¼ˆéå¸¸é‡è¦ï¼‰
            item["_model_id"] = model_id
            item["_fracture_block_index"] = block_idx
            item["_curve_index"] = curve_idx

            metrics_list.append(item)

    return metrics_list
import numpy as np
from typing import Dict, Any, List, Tuple

def extract_metrics_and_xpoints(
    sliding_results: Dict[str, Any],
    image_width_px: int
) -> Dict[str, Any]:
    """
    Extract and flatten fracture metrics from sliding_results
    and generate x_points for each curve.

    Returns:
        dict with keys:
            - curves_metrics
            - x_points_list
    """

    if not isinstance(sliding_results, dict):
        raise ValueError("sliding_results must be a dict")
    if not isinstance(image_width_px, int) or image_width_px <= 0:
        raise ValueError("image_width_px must be a positive integer")

    fracture_blocks = sliding_results.get("fracture", [])
    if not fracture_blocks:
        return {"curves_metrics": [], "x_points_list": []}

    metrics_list: List[Dict[str, Any]] = []
    x_points_list: List[np.ndarray] = []

    for block_idx, block in enumerate(fracture_blocks):
        if not isinstance(block, dict):
            continue

        model_id = block.get("model_id", "unknown")
        metrics = block.get("metrics", [])
        if not isinstance(metrics, list):
            continue

        for curve_idx, curve_metrics in enumerate(metrics):
            if not isinstance(curve_metrics, dict):
                continue

            # å¤åˆ¶ä¸€ä»½ï¼Œé¿å…æ±¡æŸ“
            item = dict(curve_metrics)
            # æ³¨å…¥å…ƒä¿¡æ¯
            item["_model_id"] = model_id
            item["_fracture_block_index"] = block_idx
            item["_curve_index"] = curve_idx
            metrics_list.append(item)

            # ç”Ÿæˆ x_points
            if all(k in item and item[k] is not None for k in ["A", "B", "C", "D"]):
                x_points_list.append(np.arange(image_width_px))

    return {"curves_metrics": metrics_list, "x_points_list": x_points_list}
# ====== overwrite_metrics å·¥å…·å‡½æ•° ======
def overwrite_metrics(target, source, flags=None, log_fn=None):
    """
    æ¡ä»¶è¦†ç›– metrics åˆ—è¡¨
    - target: åŸå§‹ metrics åˆ—è¡¨ï¼ˆä¼šè¢«è¦†ç›–ï¼‰
    - source: æ–°çš„ metrics åˆ—è¡¨
    - flags: å¯é€‰å­—å…¸ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦å¯ç”¨è¦†ç›–é€»è¾‘
    - log_fn: å¯é€‰æ—¥å¿—å‡½æ•°
    """
    enable_reflection = False
    if flags and isinstance(flags, dict):
        enable_reflection = flags.get("enable_reflection", False)

    if enable_reflection:
        if log_fn:
            log_fn(f"ğŸ”„ overwrite_metrics: è¦†ç›– {len(target)} æ¡ metrics ä¸º {len(source)} æ¡ metrics")
        # âœ… è¿”å›è¦†ç›–åçš„åˆ—è¡¨ï¼Œä¿æŒ Executor éœ€è¦çš„ key
        return {
            "derived.fracture.metrics_list": source
        }
    else:
        if log_fn:
            log_fn("âš ï¸ overwrite_metrics: æ¡ä»¶æœªæ»¡è¶³ï¼Œä¿æŒåŸ metrics")
        return {
            "derived.fracture.metrics_list": target
        }
# è§£æå·¥å…·
def resolve_masks_from_sliding_results(sliding_results, log_fn=None):
    """
    å°† sliding_results ä¸­çš„ fracture / vug mask æ˜¾å¼è§£æå‡ºæ¥
    ç”¨äº overlay_masks ä¹‹å‰
    """
    masks = []

    # -------- fracture --------
    fracture = sliding_results.get("fracture")
    if isinstance(fracture, dict):
        mask = fracture.get("mask")
        if mask:
            masks.append(mask)

    # -------- vug --------
    vug = sliding_results.get("vug")
    if isinstance(vug, dict):
        mask = vug.get("mask")
        if mask:
            masks.append(mask)

    if log_fn:
        log_fn(f"âœ… resolved masks: {masks}")

    return masks
def extract_overlay_masks(sliding_results, log_fn=None):
    """
    Executor è§„åˆ™ï¼š
    - outputs æ˜¯å®Œæ•´è·¯å¾„ â†’ return dict çš„ key å¿…é¡»å®Œå…¨ä¸€è‡´
    """

    fracture_mask = None
    vug_mask = None

    if "fracture" in sliding_results and sliding_results["fracture"]:
        fracture_mask = sliding_results["fracture"][0].get("mask")

    if "vug" in sliding_results and sliding_results["vug"]:
        vug_mask = sliding_results["vug"][0].get("mask")

    if log_fn:
        log_fn(
            f"âœ… extract_overlay_masks: "
            f"fracture={fracture_mask}, vug={vug_mask}"
        )
    print(vug_mask)
    print(fracture_mask)
    # âœ… å…³é”®ä¿®å¤ç‚¹ï¼ˆå®Œå…¨åŒ¹é… outputsï¼‰
    return {
        "derived.overlay.fracture_mask": fracture_mask,
        "derived.overlay.vug_mask": vug_mask
    }
def rebuild_unet_results(sliding_results, fracture_metrics_list, log_fn=None):
    """
    å°† DAG äº§å‡ºçš„ sliding_results + fracture_metrics_list
    é‡å»ºä¸º draw_final_results æœŸæœ›çš„ unet_results ç»“æ„
    """

    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå¦‚æœ metrics è¢«åŒ…äº†ä¸€å±‚ dictï¼Œç›´æ¥æ‹†
    if isinstance(fracture_metrics_list, dict):
        if len(fracture_metrics_list) == 1:
            fracture_metrics_list = list(fracture_metrics_list.values())[0]

    unet_results = []

    for item in sliding_results.get("fracture", []):
        unet_results.append({
            "class": "fracture",
            "mask_result": {"mask": item.get("mask")},
            "metrics_list": fracture_metrics_list   # âœ… ç°åœ¨æ˜¯ list[dict]
        })

    if log_fn:
        log_fn(f"ğŸ§± unet_results: {len(unet_results)} items rebuilt")

    return {
        "unet_results": unet_results
    }
def build_final_result_json(
    user_prompt,
    yolo_results,
    sam2_results,
    unet_results,
    sliding_results,
    params_used,
    log_fn=None
):
    import datetime
    # å‡è®¾ sliding_window_analysis è¿”å›ç»“æœå·²ç»ä¿å­˜åœ¨ vug_results é‡Œ
    #print("åŸå§‹ vug_results:", vug_results)

    # âœ… æ­£ç¡®æ‹¿å‡ºå­”æ´åˆ—è¡¨

    vug_results_list = sliding_results.get("vug", [])
    #print("å¤„ç†åçš„ vug_results_list:", vug_results_list)

    result = {
        "user_prompt": user_prompt,
        "yolo_result": yolo_results,
        "sam2_results": sam2_results,
        "unet_results": unet_results,
        "vug_results": vug_results_list,
        "params_used": params_used,
        "timestamp": datetime.datetime.now().isoformat()
    }

    if log_fn:
        log_fn("ğŸ“¦ Final result JSON assembled")
    #print(result)
    return {
        "deepseek_json": result
    }
