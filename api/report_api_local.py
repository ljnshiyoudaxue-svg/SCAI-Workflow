import os
import datetime
from flask import Flask, request, jsonify
from docx import Document
from docx.shared import Inches, Pt
from docx.oxml.ns import qn
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
from openai import OpenAI
import requests
app = Flask(__name__)

# ===============================
# ğŸ”¹ DeepSeek æŠ¥å‘Šæç¤ºè¯æ„å»º
# ===============================
# å°† DeepSeek è¾“å‡º JSON è½¬æ¢ä¸º report_api å¯ç”¨æ ¼å¼
def parse_deepseek_json(deepseek_json, px_to_m, start_depth_m):
    """
    è§£æ DeepSeek æ™ºèƒ½ä½“è¾“å‡º JSONï¼š
    - è£‚ç¼ï¼šä»…æ¥è‡ª U-Net
    - å­”æ´ï¼šæ¥è‡ª vug_results
    - æ·±åº¦ç»Ÿä¸€ç”± px â†’ m æ¢ç®—
    """

    # ================= è£‚ç¼è§£æï¼ˆä»… U-Netï¼‰ =================
    fractures = []

    for r in deepseek_json.get("unet_results", []):
        for m in r.get("metrics_list", []):
            y_offset = m.get("y_offset", 0)
            D_px = m.get("D", 0)

            depth_m = start_depth_m + (y_offset + D_px) * px_to_m

            fractures.append({
                "length_mm": m.get("length_mm", 0),
                "dip_angle_deg": m.get("å€¾è§’_deg", 0),
                "depth_m": round(depth_m, 3),
                "area_mm2": m.get("area_mm2", 0),
                "source": "unet"
            })

        # ================= å­”æ´è§£æï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰ =================
        vugs = []
        vug_results = deepseek_json.get("vug_results")
        if vug_results:
            for v in vug_results.get("window_metrics", []):
                depth_start_mm = v.get("depth_start_mm", None)
                depth_end_mm = v.get("depth_end_mm", None)

                # é˜²å¾¡å¼æ ¡éªŒ
                if depth_start_mm is None or depth_end_mm is None:
                    continue

                # ä½¿ç”¨çª—å£ä¸­ç‚¹ä½œä¸ºä»£è¡¨æ·±åº¦ï¼ˆå·¥ç¨‹ä¸Šæœ€å¸¸ç”¨ï¼‰
                depth_m = (depth_start_mm + depth_end_mm) / 2.0 / 1000.0  # mm â†’ m

                vugs.append({
                    "vug_count": v.get("vug_count", 0),
                    "area_mm2": v.get("total_area_mm2", 0),
                    "depth_m": round(depth_m, 3),
                    "CVPA": v.get("CVPA", 0),
                    "CDENS": v.get("CDENS", 0),
                    "CSIZE": v.get("CSIZE", 0),
                    "source": "unet_vug"
                })

    # ================= æ±‡æ€»æŠ¥å‘Š =================
    report_json = {
        "timestamp": deepseek_json.get("timestamp"),
        "modules_used": ["YOLO", "UNet", "SAM2"],
        "params_used": deepseek_json.get("params_used", {}),
        "fractures": fractures,
        "vugs": vugs,
        "reliability_score": "é«˜"
    }

    return report_json



def build_prompt(result_json, image_url=None):
    """æ„é€  DeepSeek ç»¼åˆåˆ†ææç¤ºè¯"""
    system_prompt = """
ä½ æ˜¯ä¸€åèµ„æ·±åœ°è´¨å·¥ç¨‹å¸ˆï¼Œä¸“é•¿äºç”µæˆåƒæµ‹äº•è§£é‡Šä¸è£‚ç¼åˆ†æã€‚
è¯·æ ¹æ®è¾“å…¥ JSON æ•°æ®ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–ã€å¯ç›´æ¥å†™å…¥æŠ¥å‘Šçš„â€œç”µæˆåƒç»¼åˆåœ°è´¨åˆ†ææŠ¥å‘Šâ€ã€‚
è¿™å£äº•æ˜¯é€‰å–çš„977.5-980æ·±åº¦æ®µï¼Œæ˜¯å®‰å±±å²©
ç”ŸæˆæŠ¥å‘Šæ—¶è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡æ’°å†™ï¼›
2. æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼ˆä»¥ Markdown æ ¼å¼ï¼‰ï¼š
   - å›¾ä»¶ç»„æˆä¸æ•°æ®è¯´æ˜
   - å‚¨å±‚ç”µæˆåƒç‰¹å¾
   - è£‚ç¼è¯†åˆ«ä¸å‘è‚²ç‰¹å¾
   - è£‚ç¼ä¸å­”æ´ç»¼åˆåˆ†æ
   - å¯é æ€§ä¸æ¨¡å‹ä¸€è‡´æ€§
   - åœ°è´¨æ„ä¹‰ä¸å·¥ç¨‹å»ºè®®
   - é™„å½•ï¼ˆå«å‚æ•°ä¸ç»Ÿè®¡è¡¨è¯´æ˜ï¼‰
3. å¯¹ YOLOã€SAM2ã€UNetã€VUG æ¨¡å—çš„æ£€æµ‹ç»“æœè¿›è¡Œç»¼åˆåˆ†æï¼›
4. è‹¥ JSON ä¸­åŒ…å«è£‚ç¼ä¸å­”æ´ä¿¡æ¯ï¼Œè¯·åˆ†æå…¶æ·±åº¦åˆ†å¸ƒã€å‘è‚²ç¨‹åº¦åŠåœ°è´¨æ„ä¹‰ï¼›
5. è‹¥ JSON ä¸­ç¼ºå°‘ä¼½é©¬æˆ–å²©æ€§ä¿¡æ¯ï¼Œè¯·åœ¨æŠ¥å‘Šä¸­è¯´æ˜ï¼›
6. æå‡ºé’ˆå¯¹é’»å®Œäº•ã€å‹è£‚æˆ–å‚¨å±‚é¢„æµ‹çš„å®šæ€§å»ºè®®ï¼›
7. è¾“å‡ºæ—¶ä¿æŒ Markdown æ ¼å¼ï¼Œæ ‡é¢˜ä½¿ç”¨â€œ#ã€##â€å±‚çº§ï¼Œæ•°å€¼å¼•ç”¨ JSON ä¸­çš„æ£€æµ‹ç»“æœã€‚
"""

    user_prompt = f"ä»¥ä¸‹æ˜¯ç³»ç»Ÿæ£€æµ‹è¾“å‡ºçš„ JSON ç»“æœï¼š\n\n```json\n{result_json}\n```\n"
    user_prompt += f"è¯·æ®æ­¤ç”Ÿæˆæ­£å¼çš„ç»¼åˆåˆ†ææŠ¥å‘Šï¼ˆé™„å›¾ï¼š{image_url or 'æ— '}ï¼‰ã€‚"
    return system_prompt, user_prompt


# ===============================
# ğŸ”¹ DeepSeek è°ƒç”¨ä¸æŠ¥å‘Šç”Ÿæˆ
# ===============================
def generate_comprehensive_report(result_json, image_path, image_url=None,
                                  output_path="DeepSeek_ComprehensiveReport.docx"):
    """ç”Ÿæˆ DeepSeek ç»¼åˆåœ°è´¨åˆ†ææŠ¥å‘Šï¼ˆé™„è¯¦ç»†è£‚ç¼/å­”æ´è¡¨æ ¼ + æ¡å½¢å›¾é«˜äº®ï¼‰"""
    #client = OpenAI(
        #api_key="",
        #base_url="")
    system_prompt, user_prompt = build_prompt(result_json, image_url=image_url)

    #response = client.chat.completions.create(
        #model="deepseek-chat",
        #messages=[
            #{"role": "system", "content": system_prompt},
            #{"role": "user", "content": user_prompt}
        #],
        #temperature=0.4,
        #max_tokens=3500
    #)
    # ===============================
    # ğŸ”¹ æ”¹ä¸ºæœ¬åœ° Ollama è°ƒç”¨
    # ===============================
    ollama_url = "http://localhost:11434/api/chat"

    payload = {
        "model": "deepseek-r1:14b",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "options": {
            "temperature": 0.4,
            "num_predict": 3500
        },
        "stream": False
    }

    response = requests.post(ollama_url, json=payload)

    if response.status_code != 200:
        raise Exception(f"Ollama è°ƒç”¨å¤±è´¥: {response.text}")

    report_text = response.json()["message"]["content"].strip()

    #report_text = response.choices[0].message.content.strip()

    # === å†™å…¥ Word æŠ¥å‘Š ===
    doc = Document()
    doc.add_heading("ç”µæˆåƒç»¼åˆåœ°è´¨åˆ†ææŠ¥å‘Š", level=1)
    doc.add_paragraph("ï¼ˆç”± DeepSeek æ™ºèƒ½æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼‰\n")

    # ä¸»ä½“å†…å®¹ï¼ˆä¿ç•™ Markdown é£æ ¼ï¼‰
    for line in report_text.split("\n"):
        if line.startswith("#"):
            doc.add_heading(line.replace("#", "").strip(), level=line.count("#"))
        elif line.startswith("- "):
            doc.add_paragraph(line[2:], style="List Bullet")
        else:
            doc.add_paragraph(line.strip())

    # === é™„å›¾ ===
    if os.path.exists(image_path):
        doc.add_heading("é™„å›¾ï¼šæ£€æµ‹ç»“æœç»¼åˆå±•ç¤º", level=2)
        doc.add_picture(image_path, width=Inches(5.5))
    else:
        doc.add_paragraph(f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼š{image_path}")

    # === é™„å½•å‚æ•°è¡¨æ ¼ ===
    doc.add_heading("é™„å½•ï¼šåˆ†æå…ƒæ•°æ®ä¸æ£€æµ‹ç»Ÿè®¡", level=2)
    params = result_json.get("params_used", {})

    # åŸºç¡€å…ƒæ•°æ®è¡¨
    table_meta = doc.add_table(rows=1, cols=2)
    table_meta.style = "Light List"
    hdr_cells = table_meta.rows[0].cells
    hdr_cells[0].text = "å‚æ•°"
    hdr_cells[1].text = "æ•°å€¼ / ä¿¡æ¯"

    metadata_items = [
        ("å›¾åƒæ·±åº¦èŒƒå›´ (mm)", params.get("image_height_mm", "æœªçŸ¥")),
        ("äº•å¾„å®½åº¦ (mm)", params.get("image_width_mm", "æœªçŸ¥")),
        ("åˆ†ææ—¶é—´", result_json.get("timestamp", "æœªçŸ¥")),
        ("æ£€æµ‹æ¨¡å—", ", ".join(result_json.get("modules_used", []))),
        ("æ£€æµ‹å¯é æ€§", result_json.get("reliability_score", "æœªçŸ¥")),
    ]

    for key, value in metadata_items:
        row_cells = table_meta.add_row().cells
        row_cells[0].text = str(key)
        row_cells[1].text = str(value)

    # === è£‚ç¼è¯¦ç»†ç»Ÿè®¡è¡¨ï¼ˆå¸¦æ¡å½¢å›¾å¯è§†åŒ–é•¿åº¦ï¼‰ ===
    fractures = result_json.get("fractures", [])
    if fractures:
        doc.add_heading("è£‚ç¼è¯¦ç»†ç»Ÿè®¡", level=2)
        table_f = doc.add_table(rows=1, cols=6)
        table_f.style = "Light List"
        hdr_cells = table_f.rows[0].cells
        hdr_cells[0].text = "ç¼–å·"
        hdr_cells[1].text = "é•¿åº¦ (mm)"
        hdr_cells[2].text = "å€¾è§’ (Â°)"
        hdr_cells[3].text = "ä½ç½®æ·±åº¦ (mm)"
        hdr_cells[4].text = "é¢ç§¯ (mmÂ²)"
        hdr_cells[5].text = "é•¿åº¦å¯è§†åŒ–"

        # è·å–æœ€å¤§é•¿åº¦ï¼Œç”¨äºæ¡å½¢æ¯”ä¾‹
        max_length = max(f.get("length", 1) for f in fractures)

        for idx, f in enumerate(fractures, 1):
            row_cells = table_f.add_row().cells
            row_cells[0].text = str(idx)
            row_cells[1].text = str(f.get("length", "æœªçŸ¥"))
            row_cells[2].text = str(f.get("dip_angle", "æœªçŸ¥"))
            row_cells[3].text = str(f.get("depth", "æœªçŸ¥"))
            row_cells[4].text = str(f.get("area", "æœªçŸ¥"))

            # æ¡å½¢å›¾è¡¨ç¤ºé•¿åº¦ï¼Œä½¿ç”¨ â€œâ–ˆâ€ å­—ç¬¦
            length_val = f.get("length", 0)
            bar_count = int((length_val / max_length) * 20) if max_length > 0 else 0
            row_cells[5].text = "â–ˆ" * bar_count

    # === å­”æ´è¯¦ç»†ç»Ÿè®¡è¡¨ï¼ˆå¸¦æ¡å½¢å›¾å¯è§†åŒ–é¢ç§¯ï¼‰ ===
    vugs = result_json.get("vugs", [])
    if vugs:
        doc.add_heading("å­”æ´è¯¦ç»†ç»Ÿè®¡", level=2)
        table_v = doc.add_table(rows=1, cols=5)
        table_v.style = "Light List"
        hdr_cells = table_v.rows[0].cells
        hdr_cells[0].text = "ç¼–å·"
        hdr_cells[1].text = "ç›´å¾„ (mm)"
        hdr_cells[2].text = "ä½ç½®æ·±åº¦ (mm)"
        hdr_cells[3].text = "é¢ç§¯ (mmÂ²)"
        hdr_cells[4].text = "é¢ç§¯å¯è§†åŒ–"

        max_area = max(v.get("area", 1) for v in vugs)
        for idx, v in enumerate(vugs, 1):
            row_cells = table_v.add_row().cells
            row_cells[0].text = str(idx)
            row_cells[1].text = str(v.get("diameter", "æœªçŸ¥"))
            row_cells[2].text = str(v.get("depth", "æœªçŸ¥"))
            row_cells[3].text = str(v.get("area", "æœªçŸ¥"))

            # æ¡å½¢å›¾è¡¨ç¤ºé¢ç§¯
            area_val = v.get("area", 0)
            bar_count = int((area_val / max_area) * 20) if max_area > 0 else 0
            row_cells[4].text = "â–ˆ" * bar_count

    # è®¾ç½®è¡¨æ ¼æ ·å¼ï¼ˆå±…ä¸­ + ä¸­æ–‡å­—ä½“ï¼‰
    for table in [table_meta, table_f if fractures else None, table_v if vugs else None]:
        if not table:
            continue
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                    paragraph.style.font.name = 'å¾®è½¯é›…é»‘'
                    paragraph.style._element.rPr.rFonts.set(qn('w:eastAsia'), 'å¾®è½¯é›…é»‘')

    # ä¿å­˜æ–‡ä»¶
    doc.save(output_path)
    return report_text, output_path


# ===============================
# ğŸ”¹ Flask API æ¥å£
# ===============================
@app.route("/generate_comprehensive_report", methods=["POST"])
def generate_comprehensive_report_api():
    """è¾“å…¥å…¨äº•æ£€æµ‹ JSON ç»“æœä¸å›¾åƒè·¯å¾„ï¼Œè¾“å‡º DeepSeek ç»¼åˆæŠ¥å‘Š"""
    data = request.json
    result_json = data.get("result", {})
    image_path = data.get("image_path", "")
    image_url = data.get("image_url", "")

    report_text, report_path = generate_comprehensive_report(result_json, image_path, image_url)

    return jsonify({
        "status": "success",
        "message": "ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ",
        "report_path": report_path,
        "report_preview": report_text[:800],
        "timestamp": datetime.datetime.now().isoformat()
    })


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=9095)
